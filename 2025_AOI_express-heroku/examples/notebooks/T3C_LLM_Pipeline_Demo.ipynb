{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOR6xtJvfjlmhEaGL0STAwz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/staceysv/tttc-light-js/blob/main/examples/notebooks/T3C_LLM_Pipeline_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Talk to the City Workflow\n",
        "\n",
        "[Talk to the City (T3C)](https://ai.objectives.institute/talk-to-the-city) summarizes and organizes diverse human perspectives for easier analysis and decision-making.\n",
        "This notebook documents and visualizes the T3C LLM pipeline, factoring out the prompts & processing and logging everything, including intermediate stages and costs, to W&B.\n",
        "\n",
        "## LLM Prompting Pipeline\n",
        "\n",
        "1. Given all comments, create a taxonomy/tree of general themes + their nested topics.\n",
        "2. For each comment, extract all claims and assign them to a specific topic node in the taxonomy tree.\n",
        "3. (no LLM calls) Sort the themes and the topics within them by frequency.\n",
        "4. Deduplicate claims in each topic.\n",
        "\n",
        "### More context\n",
        "* [T3C Github Repo](https://github.com/AIObjectives/tttc-light-js)\n",
        "* [T3C Product Overview](https://ai.objectives.institute/talk-to-the-city)\n",
        "\n",
        "### Sample CSV data\n",
        "\n",
        "* Tweets on AI safety: 76, 500, 1000, 2893\n",
        "* Reddit climate change posts titles: 100, 250, 500\n",
        "* Goodreads poetry book reviews: 500\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YbFNiYxcDMmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0 Setup & imports"
      ],
      "metadata": {
        "id": "zoyB05fkdP9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.0 Import packages, auth with W&B + OAI\n",
        "\n",
        "You'll need a [W&B API key](https://www.wandb.ai/authorize) and an OpenAI key. This colab will not log or store the keys."
      ],
      "metadata": {
        "id": "EseweiVbdfOK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbYLhN8t5GHx"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install -qqq weave\n",
        "!pip install -qqq wandb\n",
        "import wandb\n",
        "import pandas as pd\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# authenticate with OpenAI\n",
        "from getpass import getpass\n",
        "\n",
        "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
        "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
        "print(\"OpenAI API key configured\")"
      ],
      "metadata": {
        "id": "eZSuvDXidkIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1 Utils\n",
        "\n",
        "Helpful functions"
      ],
      "metadata": {
        "id": "2zICHE6-sxmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "import pytz\n",
        "\n",
        "def time_here():\n",
        "  date_format='%m/%d/%Y %H:%M:%S'\n",
        "  date = datetime.now()\n",
        "  date = date.astimezone(timezone('US/Pacific'))\n",
        "  return date.strftime(date_format)\n",
        "\n",
        "def topic_tree(taxonomy):\n",
        "  core_tree = []\n",
        "  full_tree = taxonomy[\"taxonomy\"]\n",
        "  for main_topic in full_tree:\n",
        "    topic = main_topic[\"topicName\"]\n",
        "    desc = main_topic[\"topicShortDescription\"]\n",
        "    subtopic_list = []\n",
        "    for subtopic in main_topic[\"subtopics\"]:\n",
        "      if \"subtopicName\" in subtopic:\n",
        "        sub_topic = subtopic[\"subtopicName\"]\n",
        "      else:\n",
        "        print(\"WARNING: NO TOPIC NAME\")\n",
        "        continue\n",
        "      if \"subtopicShortDescription\" in subtopic:\n",
        "        sub_desc = subtopic[\"subtopicShortDescription\"]\n",
        "      else:\n",
        "        print(\"WARNING: NO TOPIC DESCRIPTION\")\n",
        "        sub_desc = \"N/A\"\n",
        "      subtopic_list.append({sub_topic : sub_desc})\n",
        "    core_tree.append({ topic : desc, \"subtopic\" : subtopic_list})\n",
        "  return core_tree\n",
        "\n",
        "def cute_print(json_obj):\n",
        "  \"\"\"Returns a pretty version of a dictionary as properly-indented and scaled\n",
        "  json in html for at-a-glance review in W&B\"\"\"\n",
        "  str_json = json.dumps(json_obj, indent=1)\n",
        "  cute_html = '<pre id=\"json\"><font size=2>' + str_json + \"</font></pre>\"\n",
        "  return wandb.Html(cute_html)"
      ],
      "metadata": {
        "id": "Ug8oLqRbodif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.2 Input data\n",
        "\n",
        "Sample lists of comments which might be useful for testing/future exploration. Load directly from code or CSV file.\n",
        "\n",
        "Testing factors to consider:\n",
        "* duplicates: very similar/identical statements within a topic or across themes/topics\n",
        "* subject/object words, main points, variance in length and clarity\n",
        "* intensity/generality/popularity of opinions"
      ],
      "metadata": {
        "id": "5L5yZ9Q1M4OE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.2.0 Load comments from CSV\n",
        "\n",
        "Send the \"comments\" column from a dataframe through the pipeline and optionally save the source data to W&B.\n"
      ],
      "metadata": {
        "id": "rJC7H_UbNsId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_FILENAME = \"tw_76.csv\"\n",
        "df = pd.read_csv(open(CSV_FILENAME, 'r'))\n",
        "comments = df[\"comments\"]\n",
        "\n",
        "# optionally upload to W&B\n",
        "#wandb.init(project=WB_PROJECT_NAME, name=\"upload_csv_comments\", group=\"csv_comment_upload\")\n",
        "#wandb.log({\"test_comments_csv\" : df})\n",
        "#wandb.run.finish()"
      ],
      "metadata": {
        "id": "Q6wUVLEy5QEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.2.1 Load tiny test lists from code"
      ],
      "metadata": {
        "id": "RswB6iLQTrsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# past sample comments, possibly useful for testing\n",
        "\n",
        "# comments about pets\n",
        "MVP_TEST = [\"I love cats\", \"I really really love dogs\", \"I'm not sure about birds\"]\n",
        "MVP_TEST.extend([\"Cats are my favorite\", \"Dogs are the best\", \"No seriously dogs are great\", \"Birds I'm hesitant about\", \"Cats can be walked outside and they don't have to\", \"Dogs need to be walked regularly, every day\", \"Dogs can be trained to perform adorable moves on verbal command\", \"Can cats be trained?\", \"Dogs and cats are both adorable and fluffy\", \"Good pets are chill\", \"Cats are fantastic\", \"A goldfish is my top choice\"])\n",
        "MVP_TEST.extend([\"Lizards are scary\", \"Kittens are my favorite when they have snake-like scales\", \"Hairless cats are unique\", \"Flying lizards are majestic\", \"Kittens are so boring\"])\n",
        "\n",
        "# comments about scifi books\n",
        "SCIFI_TEST = [\"My favorite fantasy novel is Name of the Wind\", \"Terra Ignota is the best scifi series of all time\", \"Idk about Kim Stanley Robinson\"]\n",
        "SCIFI_TEST.extend([\"Name of the Wind is predictable and hard to read\", \"Some of Kim Stanley Robinson is boring\", \"Terra Ignota gets slow in the middle and hard to follow\",\n",
        "            \"Ada Palmer is spectacular\", \"Becky Chambers has fantastic aliens in her work\", \"Ministry for the Future and Years of Rice and Salt are really comprehensive and compelling stories\",\n",
        "            \"Do we still talk about Lord of the Rings or Game of Thrones or is epic fantasy over\", \"What about Ted Chiang he is so good\", \"Greg Egan is really good at characters and plot and hard science\",\n",
        "            \"I never finished Accelerando\", \"Ministry for the Future is about the climate transition\", \"The climate crisis is a major theme in Ministry for the Future\", \"Ministry for the Future is about climate\"])\n",
        "\n",
        "\n",
        "# *************************\n",
        "# SET OR ADD COMMENTS HERE\n",
        "# *************************\n",
        "comments = SCIFI_TEST"
      ],
      "metadata": {
        "id": "kRIHBsAAM36I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter out any non-strings\n",
        "# TODO: warn on this?\n",
        "comments = [c for c in comments if type(c) == str]\n",
        "print(\"Total comments: \", len(comments))"
      ],
      "metadata": {
        "id": "K2PfN92-JeIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.3 Prompts\n",
        "\n",
        "All the prompts for the pipeline, copied exactly from the [source repo](https://github.com/AIObjectives/tttc-light-js/blob/main/express-pipeline/src/prompts.ts) circa April 2024"
      ],
      "metadata": {
        "id": "TyjFGgWzLZRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SYS_PROMPT = \"\"\"\n",
        "You are a professional research assistant. You have helped run many public consultations,\n",
        "surveys and citizen assemblies. You have good instincts when it comes to extracting interesting insights.\n",
        "You are familiar with public consultation tools like Pol.is and you understand the benefits\n",
        "for working with very clear, concise claims that other people would be able to vote on.\n",
        "\"\"\"\n",
        "\n",
        "COMMENT_TO_TREE_PROMPT = \"\"\"\n",
        "I will give you a list of comments.\n",
        "Please propose a way to organize the information contained in these comments into topics and subtopics of interest.\n",
        "Keep the topic and subtopic names very concise and use the short description to explain what the topic is about.\n",
        "\n",
        "Return a JSON object of the form {\n",
        "  \"taxonomy\": [\n",
        "    {\n",
        "      \"topicName\": string,\n",
        "      \"topicShortDescription\": string,\n",
        "      \"subtopics\": [\n",
        "        {\n",
        "          \"subtopicName\": string,\n",
        "          \"subtopicShortDescription\": string,\n",
        "        },\n",
        "        ...\n",
        "      ]\n",
        "    },\n",
        "    ...\n",
        "  ]\n",
        "}\n",
        "Now here is the list of comments:\n",
        "\"\"\"\n",
        "\n",
        "COMMENT_TO_CLAIMS = \"\"\"\n",
        "I'm going to give you a comment made by a participant and a list of topics and subtopics which have already been extracted.\n",
        "I want you to extract a list of concise claims that the participant may support.\n",
        "We are only interested in claims that can be mapped to one of the given topic and subtopic.\n",
        "The claim must be fairly general but not a platitude.\n",
        "It must be something that other people may potentially disagree with. Each claim must also be atomic.\n",
        "For each claim, please also provide a relevant quote from the transcript.\n",
        "The quote must be as concise as possible while still supporting the argument.\n",
        "The quote doesn't need to be a logical argument.\n",
        "It could also be a personal story or anecdote illustrating why the interviewee would make this claim.\n",
        "You may use \"[...]\" in the quote to skip the less interesting bits of the quote.\n",
        "/return a JSON object of the form {\n",
        "  \"claims\": [\n",
        "    {\n",
        "      \"claim\": string, // a very concise extracted claim\n",
        "      \"quote\": string // the exact quote,\n",
        "      \"topicName\": string // from the given list of topics\n",
        "      \"subtopicName\": string // from the list of subtopics\n",
        "    },\n",
        "    // ...\n",
        "  ]\n",
        "}\n",
        "\n",
        "Now here is the list of topics/subtopics:\"\"\"\n",
        "# also include in prompt:\n",
        "# append ${taxonomy}\n",
        "# comments: And then here is the comment:\"\"\"\n",
        "\n",
        "DEDUP_PROMPT = \"\"\"\n",
        "I'm going to give you a JSON object containing a list of claims with some ids.\n",
        "I want you to remove any near-duplicate claims from the list by nesting some claims under some top-level claims.\n",
        "For example, if we have 5 claims and claim 3 and 5 are similar to claim 2, we will nest claim 3 and 5 under claim 2.\n",
        "The nesting will be represented as a JSON object where the keys are the ids of the\n",
        "top-level claims and the values are lists of ids of the nested claims.\n",
        "\n",
        "Return a JSON object of the form {\n",
        "  \"nesting\": {\n",
        "    \"claimId1\": [],\n",
        "    \"claimId2\": [\"claimId3\", \"claimId5\"],\n",
        "    \"claimId4\": []\n",
        "  }\n",
        "}\n",
        "\n",
        "And now, here are the claims:\"\"\""
      ],
      "metadata": {
        "id": "8YAouT2Jftjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1: Configure pipeline run\n",
        "\n",
        "W&B variables for convenience:\n",
        "* set RUN_NAME for each new pass through the pipeline\n",
        "* optionally set EXP_GROUP for each new set of experiments (easier to toggle visibility/metrics by new logic/day/coding session/etc)\n",
        "\n"
      ],
      "metadata": {
        "id": "30QoaQXjIVXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RUN_NAME = \"reddit_climate_change_100\"\n",
        "WB_PROJECT_NAME = \"t3c_pipeline\"\n",
        "EXP_GROUP = \"week_0\""
      ],
      "metadata": {
        "id": "Yme7kQSuUKFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# maps to gpt-4-0125-preview - token costs:\n",
        "# $10/1M in, $30/1M out = $0.1/10K in, $0.3/10K out\n",
        "MODEL = \"gpt-4-turbo-preview\"\n",
        "COST_IN_PER_10K = 0.1\n",
        "COST_OUT_PER_10K = 0.3\n",
        "\n",
        "# periodically update from W&B\n",
        "AVG_TREE_LEN_TOKS = 614\n",
        "AVG_CLAIM_TOKS_OUT = 130\n",
        "AVG_TOPIC_COUNT = 12\n",
        "AVG_DEDUP_INPUT_TOK = 12\n",
        "# TODO: this is the weakest approximation, make more rigorous\n",
        "AVG_DEDUPED_CLAIMS_FACTOR = 0.6\n",
        "\n",
        "guess_cost = 0\n",
        "actual_cost = 0\n",
        "\n",
        "# log csv output (to spreadsheet)\n",
        "#name,group,time,rows,chars,guess_cost,actual_cost,1_cost,2_cost,4_cost,num_themes,num_topics,num_claims\n",
        "#eventually we want these more granular and/or averaged?"
      ],
      "metadata": {
        "id": "hrzvigtptfsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Estimate costs\n",
        "\n",
        "1 token ~= 4 characters of text for common English text. This translates to roughly ¾ of a word (so 100 tokens ~= 75 words).\n",
        "\n",
        "Estimate costs for each step, input and output:\n",
        "* Step 1: input is total prompt + comments; output is average tree length in tokens for now\n",
        "* Step 2: input is, for each comment, (SYS_PROMPT + COMMENT_TO_CLAIMS_PROMPT + len(taxonomy output of Step 1)) + total len(comments); output is, for each comment, average length of claim output\n",
        "* Step 3: input is, for each topic with duplicate claims, which we approximate as the cube root of total comments, (SYS_PROMPT + DEDUP_PROMPT) * average deduplication input tokens; output is the average deduplciated claims factor between total input tokens and deduped output\n",
        "\n"
      ],
      "metadata": {
        "id": "12UZJlxObl2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# estimate cost before completing template\n",
        "comments_total = sum([len(c) for c in comments])\n",
        "N_sys_prompt = len(SYS_PROMPT)\n",
        "\n",
        "# inputs in tokens\n",
        "step_1_tok_in = (N_sys_prompt + len(COMMENT_TO_TREE_PROMPT) + comments_total) / 4.0\n",
        "step_2_tok_in = (comments_total/4.0) + len(comments) * (((N_sys_prompt + len(COMMENT_TO_CLAIMS))/ 4.0) + AVG_TREE_LEN_TOKS)\n",
        "step_4_tok_in = ((N_sys_prompt + len(DEDUP_PROMPT)) /4.0) * (len(comments) ** 0.33) * AVG_DEDUP_INPUT_TOK\n",
        "# convert input token counts to $\n",
        "cost_in = ((step_1_tok_in + step_2_tok_in + step_4_tok_in) * COST_IN_PER_10K) / 10000.0\n",
        "\n",
        "# outputs in tokens\n",
        "step_1_tok_out = AVG_TREE_LEN_TOKS\n",
        "step_2_tok_out = len(comments) * AVG_CLAIM_TOKS_OUT\n",
        "step_4_tok_out = len(comments) * AVG_DEDUPED_CLAIMS_FACTOR\n",
        "# convert output token counts to $\n",
        "cost_out = ((step_1_tok_out + step_2_tok_out + step_4_tok_out) * COST_OUT_PER_10K) / 10000.0\n",
        "\n",
        "print(\"estimated costs: IN: \", cost_in, \" OUT: \", cost_out)\n",
        "guess_cost = cost_in + cost_out\n",
        "print(\"guess total total: $\", guess_cost)"
      ],
      "metadata": {
        "id": "uVkAp0PBeoUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3: Run pipeline"
      ],
      "metadata": {
        "id": "WFBakBgKe9wO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Comments to tree\n",
        "\n",
        "Given the full list of comments, call LLM to create a taxonomy of main themes and nested topics with short descriptions."
      ],
      "metadata": {
        "id": "eyrJtqJyLzwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "import wandb\n",
        "import weave\n",
        "import json\n",
        "\n",
        "weave.init(WB_PROJECT_NAME)\n",
        "wandb.init(project = WB_PROJECT_NAME, name=RUN_NAME, group=EXP_GROUP,\n",
        "           # TODO: add more config here\n",
        "           config={\"model\" : MODEL,\n",
        "                   \"$_in_10K\" : COST_IN_PER_10K,\n",
        "                   \"$_out_10K\" : COST_OUT_PER_10K,\n",
        "                   \"cost_guess\" : guess_cost\n",
        "                  })\n",
        "\n",
        "# track token counts+costs for pipeline\n",
        "TK_TOT = 0\n",
        "TK_IN = 0\n",
        "TK_OUT = 0\n",
        "NUM_THEMES = 0\n",
        "NUM_TOPICS = 0\n",
        "actual_cost = 0\n",
        "\n",
        "@weave.op()\n",
        "def comments_to_tree(comments:list)-> dict:\n",
        "    client = OpenAI()\n",
        "\n",
        "    # append comments to prompt\n",
        "    full_prompt = COMMENT_TO_TREE_PROMPT\n",
        "    for comment in comments:\n",
        "      full_prompt += \"\\n\" + comment\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": SYS_PROMPT\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": full_prompt\n",
        "        }\n",
        "        ],\n",
        "        temperature=0.0,\n",
        "        response_format={ \"type\": \"json_object\" }\n",
        "    )\n",
        "    tree = response.choices[0].message.content\n",
        "    return {\"tree\" : json.loads(tree), \"usage\" : response.usage}\n",
        "\n",
        "# estimate cost before completing template\n",
        "comment_lengths = [len(c) for c in comments]\n",
        "wandb.log({\"comm_N\" : len(comments), \"comm_text_len\": sum(comment_lengths), \"comm_bins\" : comment_lengths})\n",
        "\n",
        "with weave.attributes({\"model\" : MODEL, \"stage\" : \"1_comments_to_tree\"}):\n",
        "  resp = comments_to_tree(comments)\n",
        "  taxonomy = resp[\"tree\"]\n",
        "  usage = resp[\"usage\"]\n",
        "  NUM_THEMES = len(taxonomy[\"taxonomy\"])\n",
        "  subtopics = [len(t[\"subtopics\"]) for t in taxonomy[\"taxonomy\"]]\n",
        "  NUM_TOPICS = sum(subtopics)\n",
        "  # optional: print outputs and tree metrics\n",
        "  print(taxonomy)\n",
        "  print(usage)\n",
        "  print(NUM_THEMES, NUM_TOPICS, subtopics)\n",
        "\n",
        "# in case comments are empty / for W&B Table logging\n",
        "comment_list = \"none\"\n",
        "if len(comments) > 1:\n",
        "  comment_list = \"\\n\".join(comments)\n",
        "tl = [[comment_list, cute_print(topic_tree(taxonomy)), json.dumps(taxonomy,indent=1)]]\n",
        "\n",
        "# update token counts\n",
        "TK_TOT += usage.total_tokens\n",
        "TK_IN += usage.prompt_tokens\n",
        "TK_OUT += usage.completion_tokens\n",
        "\n",
        "actual_1_cost = (COST_IN_PER_10K * TK_IN + COST_OUT_PER_10K * TK_OUT) / 10000.0\n",
        "print(\"Step 1, actual cost $\", actual_1_cost)\n",
        "actual_cost += actual_1_cost\n",
        "\n",
        "wandb.log({\n",
        "    \"u/1/N_tok\": usage.total_tokens,\n",
        "    \"u/1/in_tok\" : usage.prompt_tokens,\n",
        "    \"u/1/out_tok\": usage.completion_tokens,\n",
        "    \"u/1/cost\" : actual_1_cost,\n",
        "    \"u/N/N_tok\" : TK_TOT,\n",
        "    \"u/N/in_tok\": TK_IN,\n",
        "    \"u/N/out_tok\" : TK_OUT,\n",
        "    \"u/N/cost\" : actual_cost,\n",
        "    \"rows_to_tree\" : wandb.Table(data=tl, columns = [\"comments\", \"taxonomy\", \"raw_llm_out\"]),\n",
        "    # track tree shape\n",
        "    \"num_themes\" : NUM_THEMES,\n",
        "    \"num_topics\" : NUM_TOPICS,\n",
        "    \"topic_tree\" : subtopics\n",
        "})"
      ],
      "metadata": {
        "id": "JILGhL2r5lNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: One comment > extract claims\n",
        "\n",
        "For each comment, extract claims and assign to a specific subtopic in the given taxonomy."
      ],
      "metadata": {
        "id": "Izyy-lyysAoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weave.init(WB_PROJECT_NAME)\n",
        "\n",
        "@weave.op()\n",
        "def comment_to_claims(comment:str)-> dict:\n",
        "    client = OpenAI()\n",
        "\n",
        "    # add taxonomy and comment to prompt template\n",
        "    full_prompt = COMMENT_TO_CLAIMS\n",
        "    taxonomy_string = json.dumps(taxonomy, indent=1)\n",
        "    full_prompt += \"\\n\" + taxonomy_string + \"\\nAnd then here is the comment:\\n\" + comment\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": SYS_PROMPT\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": full_prompt\n",
        "        }\n",
        "        ],\n",
        "        temperature=0.0,\n",
        "        response_format={ \"type\": \"json_object\" }\n",
        "    )\n",
        "    claims = response.choices[0].message.content\n",
        "    return {\"claims\" : json.loads(claims), \"usage\" : response.usage}\n",
        "\n",
        "TK_2_IN = 0\n",
        "TK_2_OUT = 0\n",
        "TK_2_TOT = 0\n",
        "\n",
        "c2c = []\n",
        "c2c_html = []\n",
        "with weave.attributes({\n",
        "    \"model\" : MODEL, \"stage\" : \"2_comment_to_claims\", \"run\" : RUN_NAME}):\n",
        "  for comment in comments:\n",
        "    resp = comment_to_claims(comment)\n",
        "    claims = resp[\"claims\"]\n",
        "    usage = resp[\"usage\"]\n",
        "    print(comment)\n",
        "    print(claims)\n",
        "    c2c.append(claims)\n",
        "\n",
        "    # format for logging to W&B\n",
        "    viz_claims = cute_print(claims)\n",
        "    c2c_html.append([comment, viz_claims, json.dumps(claims,indent=1)])\n",
        "\n",
        "    TK_2_IN += usage.prompt_tokens\n",
        "    TK_2_OUT += usage.completion_tokens\n",
        "    TK_2_TOT += usage.total_tokens\n",
        "\n",
        "    TK_TOT += usage.total_tokens\n",
        "    TK_IN += usage.prompt_tokens\n",
        "    TK_OUT += usage.completion_tokens\n",
        "\n",
        "    # update per-comment tokens\n",
        "    wandb.log({\n",
        "      \"u/2/s_N_tok\": usage.total_tokens,\n",
        "      \"u/2/s_in_tok\" : usage.prompt_tokens,\n",
        "      \"u/2/s_out_tok\": usage.completion_tokens,\n",
        "      \"u/2/t_N_tok\": TK_2_TOT,\n",
        "      \"u/2/t_in_tok\" : TK_2_IN,\n",
        "      \"u/2/t_out_tok\": TK_2_OUT\n",
        "    })\n",
        "\n",
        "actual_2_cost = (COST_IN_PER_10K * TK_2_IN + COST_OUT_PER_10K * TK_2_OUT) / 10000.0\n",
        "print(\"Step 2, actual cost $\", actual_2_cost)\n",
        "actual_cost += actual_2_cost\n",
        "\n",
        "wandb.log({\n",
        "    \"u/N/N_tok\" : TK_TOT,\n",
        "    \"u/N/in_tok\": TK_IN,\n",
        "    \"u/N/out_tok\" : TK_OUT,\n",
        "    \"u/N/cost\" : actual_cost,\n",
        "    \"u/2/cost\" : actual_2_cost,\n",
        "    \"row_to_claims\" : wandb.Table(data=c2c_html, columns = [\"comments\", \"claims\", \"raw_llm_out\"])\n",
        "})"
      ],
      "metadata": {
        "id": "ETtcxo20uxFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: [non-LLM] Count + sort by claims DESC\n",
        "\n",
        "Sort the taxonomy by such that themes and topics with the most claims appear first. Note that this pipeline stage doesn't call any LLMs."
      ],
      "metadata": {
        "id": "Ab-Blzxp2t9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_TOPICS_STEP_3 = 0\n",
        "NUM_CLAIMS = 0\n",
        "\n",
        "# sort the taxonomy so the themes with the most total claims, and within each theme,\n",
        "# the topics with the most claims, appear first\n",
        "def sort_taxonomy(tree, c2c):\n",
        "  node_counts = {}\n",
        "  for cmt, cmt_claims in zip(comments, c2c):\n",
        "    if \"claims\" not in cmt_claims:\n",
        "      print(\"warning: no claims!\")\n",
        "      continue\n",
        "    for claim in cmt_claims[\"claims\"]:\n",
        "      if claim[\"topicName\"] in node_counts:\n",
        "        node_counts[claim[\"topicName\"]][\"total\"] += 1\n",
        "        if claim[\"subtopicName\"] in node_counts[claim[\"topicName\"]][\"subtopics\"]:\n",
        "          node_counts[claim[\"topicName\"]][\"subtopics\"][claim[\"subtopicName\"]][\"total\"] += 1\n",
        "          node_counts[claim[\"topicName\"]][\"subtopics\"][claim[\"subtopicName\"]][\"claims\"].append(claim[\"claim\"])\n",
        "        else:\n",
        "          node_counts[claim[\"topicName\"]][\"subtopics\"][claim[\"subtopicName\"]] = { \"total\" : 1, \"claims\" : [claim[\"claim\"]]}\n",
        "      else:\n",
        "        node_counts[claim[\"topicName\"]] = {\"total\" : 1, \"subtopics\" : {claim[\"subtopicName\"] : {\"total\" : 1, \"claims\" : [claim[\"claim\"]]}}}\n",
        "  return node_counts\n",
        "\n",
        "# log sorted taxonomy\n",
        "sorted_taxonomy = sort_taxonomy(taxonomy, c2c)\n",
        "print(sorted_taxonomy)\n",
        "html_data = [[cute_print(sorted_taxonomy), json.dumps(sorted_taxonomy, indent=1)]]\n",
        "\n",
        "# count number of claims in each topic node of the outline\n",
        "for theme, topics in sorted_taxonomy.items():\n",
        "  for theme_key, topic_details in topics.items():\n",
        "    if theme_key == \"subtopics\":\n",
        "        for topic_key, claim_details in topic_details.items():\n",
        "            NUM_CLAIMS += claim_details[\"total\"]\n",
        "        NUM_TOPICS_STEP_3 += len(topic_details)\n",
        "\n",
        "print(NUM_TOPICS_STEP_3)\n",
        "print(NUM_CLAIMS)\n",
        "wandb.log({\"sort_tree\" : wandb.Table(data=html_data, columns = [\"sorted_taxonomy\", \"raw_llm_output\"])})"
      ],
      "metadata": {
        "id": "mCHYoEpH29ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optional: print the topics\n",
        "for k, v in sorted_taxonomy.items():\n",
        "  for i, j in v.items():\n",
        "    if i == \"subtopics\":\n",
        "      print(j.keys())"
      ],
      "metadata": {
        "id": "JCKplSYc5GDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Dedup claims in each subtopic\n",
        "\n",
        "Find similar claims in the list for each subtopic. This logic could be much cleaner."
      ],
      "metadata": {
        "id": "tcBsPcI_Csol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weave.init(WB_PROJECT_NAME)\n",
        "\n",
        "@weave.op()\n",
        "def dedup_claims(claims:str)-> dict:\n",
        "    client = OpenAI()\n",
        "\n",
        "    # add claims with enumerated ids\n",
        "    full_prompt = DEDUP_PROMPT\n",
        "    for i, rc in enumerate(claims):\n",
        "      full_prompt += \"\\nclaimId\"+str(i)+ \": \" + rc\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": SYS_PROMPT\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": full_prompt\n",
        "        }\n",
        "        ],\n",
        "        temperature=0.0,\n",
        "        response_format={ \"type\": \"json_object\" }\n",
        "    )\n",
        "    deduped_claims = response.choices[0].message.content\n",
        "    return {\"dedup_claims\" : json.loads(deduped_claims), \"usage\" : response.usage}\n",
        "\n",
        "TK_4_IN = 0\n",
        "TK_4_OUT = 0\n",
        "TK_4_TOT = 0\n",
        "\n",
        "print(c2c)\n",
        "nested_claims = {}\n",
        "dupe_counts = {}\n",
        "with weave.attributes({\"model\" : MODEL, \"stage\" : \"4_dedup_claims\", \"run\" : RUN_NAME}):\n",
        "  tl_data = []\n",
        "  for topic, subt in sorted_taxonomy.items():\n",
        "    for sub_topic, subtd in subt[\"subtopics\"].items():\n",
        "      print(\"num claims in topic: \", len(subtd[\"claims\"]))\n",
        "      # don't dedup solo claims\n",
        "      if len(subtd[\"claims\"]) > 1:\n",
        "        resp = dedup_claims(subtd[\"claims\"])\n",
        "        deduped_claims = resp[\"dedup_claims\"]\n",
        "        usage = resp[\"usage\"]\n",
        "\n",
        "        # let's check if they're duplicated?\n",
        "        # this is harder than we thought!\n",
        "        has_dupes = False\n",
        "        if \"nesting\" in deduped_claims:\n",
        "          for claim_key, claim_vals in deduped_claims[\"nesting\"].items():\n",
        "            if len(claim_vals) > 0:\n",
        "              has_dupes = True\n",
        "              # extract index...\n",
        "              ckey = int(claim_key[-1:])\n",
        "              dupe_keys = [int(c_key[-1:]) for c_key in claim_vals]\n",
        "              dupe_counts[subtd[\"claims\"][ckey]] = dupe_keys\n",
        "\n",
        "        # for logging to wandb\n",
        "        tl_data.append([\"\\n\".join(subtd[\"claims\"]), cute_print(deduped_claims), json.dumps(deduped_claims, indent=1)])\n",
        "\n",
        "        # append dupe claims & filter\n",
        "        if has_dupes:\n",
        "          nested_claims[sub_topic] = {\"dupes\" : deduped_claims, \"og\" : subtd[\"claims\"]}\n",
        "        wandb.log({\n",
        "            \"u/4/s_N_tok\": usage.total_tokens,\n",
        "            \"u/4/s_in_tok\" : usage.prompt_tokens,\n",
        "            \"u/4/s_out_tok\": usage.completion_tokens,\n",
        "            \"u/4/t_N_tok\": TK_4_TOT,\n",
        "            \"u/4/t_in_tok\" : TK_4_IN,\n",
        "            \"u/4/t_out_tok\": TK_4_OUT\n",
        "        })\n",
        "        TK_4_TOT += usage.total_tokens\n",
        "        TK_4_IN += usage.prompt_tokens\n",
        "        TK_4_OUT += usage.completion_tokens\n",
        "        TK_TOT += usage.total_tokens\n",
        "        TK_IN += usage.prompt_tokens\n",
        "        TK_OUT += usage.completion_tokens\n",
        "\n",
        "  actual_4_cost = (COST_IN_PER_10K * TK_4_IN + COST_OUT_PER_10K * TK_4_OUT) / 10000.0\n",
        "  print(\"Step 4, actual cost $\", actual_4_cost)\n",
        "  actual_cost += actual_4_cost\n",
        "\n",
        "  wandb.log({\n",
        "      \"u/N/N_tok\" : TK_TOT,\n",
        "      \"u/N/in_tok\": TK_IN,\n",
        "      \"u/N/out_tok\" : TK_OUT,\n",
        "      \"u/4/cost\" : actual_4_cost,\n",
        "      \"u/N/cost\" : actual_cost,\n",
        "      \"dedup_subclaims\" : wandb.Table(data=tl_data, columns = [\"sub_claim_list\", \"deduped_claims\", \"raw_llm_output\"]),\n",
        "      \"num_claims\" : NUM_CLAIMS,\n",
        "      \"num_topics_post_sort\" : NUM_TOPICS_STEP_3\n",
        "})\n",
        "\n",
        "print(json.dumps(dupe_counts, indent=2))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-JocF-KDDrjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4: Save Approximate T3C Report\n",
        "\n",
        "Merge duplicate claims and log a simplified T3C report to W&B."
      ],
      "metadata": {
        "id": "HmF7k0ubVPah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def synth_t3c_report(ttree, dupes):\n",
        "  ltree = {}\n",
        "  for theme, theme_d in ttree.items():\n",
        "    theme_total = 0\n",
        "    topic_list = {}\n",
        "    for topic, topic_d in theme_d[\"subtopics\"].items():\n",
        "      theme_total += topic_d[\"total\"]\n",
        "      if topic in nested_claims:\n",
        "        # this one has some dupes\n",
        "        # for each duplicate claim, we list the duplicate ids\n",
        "        # but we don't currently merge them as \"similar claims\"\n",
        "        rerank = {}\n",
        "        for c in topic_d[\"claims\"]:\n",
        "          if c in dupe_counts:\n",
        "            new_label = c + \" (\" + str(len(dupe_counts[c]) + 1) + \"x:\"\n",
        "            for ckey in dupe_counts[c]:\n",
        "              new_label += \" \" + str(ckey) + \",\"\n",
        "            new_label += \")\"\n",
        "            rerank[new_label] = len(dupe_counts[c])\n",
        "          else:\n",
        "            rerank[c] = 0\n",
        "        ranked = sorted(rerank.items(), key=lambda x: x[1], reverse=True)\n",
        "        new_claims = [r[0] for r in ranked]\n",
        "        print(new_claims)\n",
        "        topic_list[topic] = {\"total\" : topic_d[\"total\"], \"claims\" : new_claims}\n",
        "      else:\n",
        "        topic_list[topic] = {\"total\" : topic_d[\"total\"], \"claims\" : topic_d[\"claims\"]}\n",
        "\n",
        "    # sort topics\n",
        "    sorted_topics = sorted(topic_list.items(), key=lambda x: x[1][\"total\"], reverse=True)\n",
        "\n",
        "    ltree[theme] = {\"total\" : theme_total, \"topics\" : sorted_topics}\n",
        "\n",
        "  # sort full tree\n",
        "  sorted_tree = sorted(ltree.items(), key=lambda x: x[1][\"total\"], reverse=True)\n",
        "  return sorted_tree\n",
        "\n",
        "ltree = synth_t3c_report(sorted_taxonomy, dupe_counts)\n",
        "print(json.dumps(ltree, indent=4))\n",
        "\n",
        "# log sorted taxonomy\n",
        "html_data = [[cute_print(ltree), json.dumps(ltree, indent=1)]]\n",
        "\n",
        "# log final costs\n",
        "total_run_cost = TK_IN * (COST_IN_PER_10K/10000.0) + TK_OUT * (COST_OUT_PER_10K/10000.0)\n",
        "print(\"guessed: \", guess_cost)\n",
        "print(\"total from TK: \", total_run_cost)\n",
        "print(\"total from math: \", actual_cost)\n",
        "\n",
        "# log sheet\n",
        "#name,group,time,rows,chars,guess_cost,tok_cost,actual_cost,1_cost,2_cost,4_cost,num_themes,num_topics,num_claims\n",
        "#eventually we want these more..granular/averaged?\n",
        "\n",
        "log_row = [RUN_NAME, EXP_GROUP, time_here(),len(comments),comments_total,round(guess_cost,2),\n",
        "           round(total_run_cost, 2),round(actual_cost,2),round(actual_1_cost,2),round(actual_2_cost,2),round(actual_4_cost,2),\n",
        "           NUM_THEMES, NUM_TOPICS_STEP_3, NUM_CLAIMS ]\n",
        "csv_log = \",\".join([str(x) for x in log_row])\n",
        "print(csv_log)\n",
        "\n",
        "wandb.log({\n",
        "    \"cost/tok_total\" :  total_run_cost,\n",
        "    \"cost/actual\" : actual_cost,\n",
        "    \"cost/1\": actual_1_cost,\n",
        "    \"cost/2\" : actual_2_cost,\n",
        "    \"cost/4\" : actual_4_cost,\n",
        "    \"csv_log\" : csv_log,\n",
        "    \"t3c_report\" : wandb.Table(data=html_data, columns = [\"t3c_report\", \"raw_llm_output\"])})\n",
        "\n",
        "wandb.run.finish()"
      ],
      "metadata": {
        "id": "jleyPa2AXNOG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}