"use strict";(self.webpackChunknext_client=self.webpackChunknext_client||[]).push([[515],{"../common/morphisms/pipeline.ts":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{kW:()=>getReportDataObj});__webpack_require__("../common/schema.ts");var uuid__WEBPACK_IMPORTED_MODULE_1__=__webpack_require__("../common/node_modules/uuid/dist/esm-browser/v4.js");const uuid=()=>(0,uuid__WEBPACK_IMPORTED_MODULE_1__.A)(),buildSourceMap=sourceRows=>sourceRows.reduce(((accum,curr)=>(accum[curr.id]={id:uuid(),data:["text",{text:curr.comment}]},accum)),{}),numberClaims=()=>{let i=0;const alreadyNumberedIds=new Set,x=(clm,sourceMap,claimMap)=>alreadyNumberedIds.has(clm.claimId)?claimMap[clm.claimId]:(alreadyNumberedIds.add(clm.claimId),i++,{id:uuid(),title:clm.claim,quotes:[getQuote(clm,sourceMap)],number:i,similarClaims:clm.duplicates?clm.duplicates.map((clm=>x(clm,sourceMap,claimMap))):[]});return x},buildClaimsMap=(pipeline,sourceMap)=>{const allClaims=pipeline.tree.flatMap((topic=>topic.subtopics.flatMap((subtopic=>subtopic.claims.concat(subtopic.claims.flatMap((claim=>claim.duplicates))))))),createClaim=numberClaims();return allClaims.reduce(((accum,curr)=>(accum[curr.claimId]=createClaim(curr,sourceMap,accum),curr.duplicates&&curr.duplicates.forEach(((dup,i)=>{accum[dup.claimId]=accum[curr.claimId].similarClaims[i]})),accum)),{})},getQuote=(claim,sourceMap)=>({id:uuid(),text:claim.quote,reference:{id:uuid(),sourceId:sourceMap[claim.commentId].id,data:["text",{startIdx:getReferenceStartIndex(claim,sourceMap[claim.commentId].data[1].text),endIdx:getReferenceEndIndex(claim,sourceMap[claim.commentId].data[1].text)}]}}),getReferenceStartIndex=(clm,fullText)=>fullText.indexOf(clm.quote),getReferenceEndIndex=(clm,fullText)=>getReferenceStartIndex(clm,fullText)+clm.quote.length,getSubtopicsFromLLMSubTopics=claimMap=>subtopics=>subtopics.map((subtopic=>({id:uuid(),title:subtopic.subtopicName,description:subtopic.subtopicShortDescription,claims:subtopic.claims.map((claim=>claimMap[claim.claimId]))}))),getTopicsFromTaxonomy=claimMap=>tree=>tree.map((leaf=>({id:uuid(),title:leaf.topicName,description:leaf.topicShortDescription,subtopics:getSubtopicsFromLLMSubTopics(claimMap)(leaf.subtopics)}))),getReportDataObj=pipelineOutput=>{const sourceMap=buildSourceMap(pipelineOutput.data),claimMap=buildClaimsMap(pipelineOutput,sourceMap);return{title:pipelineOutput.title,description:pipelineOutput.description,date:(new Date).toISOString(),topics:getTopicsFromTaxonomy(claimMap)(pipelineOutput.tree),sources:pipelineOutput.data.map((row=>sourceMap[row.id]))}}},"../common/schema.ts":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{At:()=>topic,B7:()=>claim,EN:()=>reportDataObj,SG:()=>pipelineStages,gz:()=>subtopic,hD:()=>quote,hr:()=>llmPipelineOutput,ir:()=>reference,sP:()=>source});var zod__WEBPACK_IMPORTED_MODULE_0__=__webpack_require__("../common/node_modules/zod/lib/index.mjs");const sourceRow=zod__WEBPACK_IMPORTED_MODULE_0__.z.object({comment:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),id:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),interview:zod__WEBPACK_IMPORTED_MODULE_0__.z.string().optional(),video:zod__WEBPACK_IMPORTED_MODULE_0__.z.string().optional(),timestamp:zod__WEBPACK_IMPORTED_MODULE_0__.z.string().optional()}),csvDataPayload=zod__WEBPACK_IMPORTED_MODULE_0__.z.tuple([zod__WEBPACK_IMPORTED_MODULE_0__.z.literal("csv"),sourceRow.array()]),googleSheetData=zod__WEBPACK_IMPORTED_MODULE_0__.z.object({url:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),pieChartColumns:zod__WEBPACK_IMPORTED_MODULE_0__.z.string().array().optional(),filterEmails:zod__WEBPACK_IMPORTED_MODULE_0__.z.string().array().optional(),oneSubmissionPerEmail:zod__WEBPACK_IMPORTED_MODULE_0__.z.boolean()}),googleSheetDataPayload=zod__WEBPACK_IMPORTED_MODULE_0__.z.tuple([zod__WEBPACK_IMPORTED_MODULE_0__.z.literal("googlesheet"),googleSheetData]),llmPieChart=(zod__WEBPACK_IMPORTED_MODULE_0__.z.union([csvDataPayload,googleSheetDataPayload]),zod__WEBPACK_IMPORTED_MODULE_0__.z.object({title:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),items:zod__WEBPACK_IMPORTED_MODULE_0__.z.object({label:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),count:zod__WEBPACK_IMPORTED_MODULE_0__.z.number()}).array()})),oldclaim=(zod__WEBPACK_IMPORTED_MODULE_0__.z.object({apiKey:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),title:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),question:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),description:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),systemInstructions:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),clusteringInstructions:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),extractionInstructions:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),dedupInstructions:zod__WEBPACK_IMPORTED_MODULE_0__.z.string()}),zod__WEBPACK_IMPORTED_MODULE_0__.z.object({model:zod__WEBPACK_IMPORTED_MODULE_0__.z.string().optional(),batchSize:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),filename:zod__WEBPACK_IMPORTED_MODULE_0__.z.string()}),zod__WEBPACK_IMPORTED_MODULE_0__.z.object({model:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),apiKey:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),data:sourceRow.array(),title:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),question:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),pieCharts:llmPieChart.array().optional(),description:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),systemInstructions:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),clusteringInstructions:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),extractionInstructions:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),dedupInstructions:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),batchSize:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),filename:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),googleSheet:zod__WEBPACK_IMPORTED_MODULE_0__.z.object({url:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),pieChartColumns:zod__WEBPACK_IMPORTED_MODULE_0__.z.string().array().optional(),filterEmails:zod__WEBPACK_IMPORTED_MODULE_0__.z.string().array().optional(),oneSubmissionPerEmail:zod__WEBPACK_IMPORTED_MODULE_0__.z.boolean()}).optional()}),zod__WEBPACK_IMPORTED_MODULE_0__.z.custom()),llmSubtopic=(zod__WEBPACK_IMPORTED_MODULE_0__.z.object({get:zod__WEBPACK_IMPORTED_MODULE_0__.z.function().args(zod__WEBPACK_IMPORTED_MODULE_0__.z.string()).returns(zod__WEBPACK_IMPORTED_MODULE_0__.z.any()),set:zod__WEBPACK_IMPORTED_MODULE_0__.z.function().args(zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),zod__WEBPACK_IMPORTED_MODULE_0__.z.any()).returns(zod__WEBPACK_IMPORTED_MODULE_0__.z.void())}),zod__WEBPACK_IMPORTED_MODULE_0__.z.object({start:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),costs:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),prompt_tokens:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),completion_tokens:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),unmatchedClaims:zod__WEBPACK_IMPORTED_MODULE_0__.z.array(oldclaim),end:zod__WEBPACK_IMPORTED_MODULE_0__.z.number().optional(),duration:zod__WEBPACK_IMPORTED_MODULE_0__.z.string().optional()}),zod__WEBPACK_IMPORTED_MODULE_0__.z.object({subtopicName:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),subtopicShortDescription:zod__WEBPACK_IMPORTED_MODULE_0__.z.string().optional(),subtopicId:zod__WEBPACK_IMPORTED_MODULE_0__.z.string().optional(),claimsCount:zod__WEBPACK_IMPORTED_MODULE_0__.z.number().optional(),claims:zod__WEBPACK_IMPORTED_MODULE_0__.z.array(oldclaim).optional()})),llmTopic=zod__WEBPACK_IMPORTED_MODULE_0__.z.object({topicName:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),topicShortDescription:zod__WEBPACK_IMPORTED_MODULE_0__.z.string().optional(),topicId:zod__WEBPACK_IMPORTED_MODULE_0__.z.string().optional(),claimsCount:zod__WEBPACK_IMPORTED_MODULE_0__.z.number().optional(),subtopics:zod__WEBPACK_IMPORTED_MODULE_0__.z.array(llmSubtopic)}),taxonomy=zod__WEBPACK_IMPORTED_MODULE_0__.z.array(llmTopic),llmPipelineOutput=zod__WEBPACK_IMPORTED_MODULE_0__.z.object({data:zod__WEBPACK_IMPORTED_MODULE_0__.z.array(sourceRow),title:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),question:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),pieChart:zod__WEBPACK_IMPORTED_MODULE_0__.z.array(llmPieChart).optional(),description:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),systemInstructions:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),clusteringInstructions:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),extractionInstructions:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),batchSize:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),tree:taxonomy,start:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),costs:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),end:zod__WEBPACK_IMPORTED_MODULE_0__.z.number().optional(),duration:zod__WEBPACK_IMPORTED_MODULE_0__.z.string().optional()}),textMediaSource=(zod__WEBPACK_IMPORTED_MODULE_0__.z.record(zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),sourceRow),zod__WEBPACK_IMPORTED_MODULE_0__.z.tuple([zod__WEBPACK_IMPORTED_MODULE_0__.z.literal("text"),zod__WEBPACK_IMPORTED_MODULE_0__.z.object({text:zod__WEBPACK_IMPORTED_MODULE_0__.z.string()})])),videoMediaSource=zod__WEBPACK_IMPORTED_MODULE_0__.z.tuple([zod__WEBPACK_IMPORTED_MODULE_0__.z.literal("video"),zod__WEBPACK_IMPORTED_MODULE_0__.z.object({link:zod__WEBPACK_IMPORTED_MODULE_0__.z.string()})]),audioMediaSource=zod__WEBPACK_IMPORTED_MODULE_0__.z.tuple([zod__WEBPACK_IMPORTED_MODULE_0__.z.literal("audio"),zod__WEBPACK_IMPORTED_MODULE_0__.z.object({link:zod__WEBPACK_IMPORTED_MODULE_0__.z.string()})]),mediaSources=zod__WEBPACK_IMPORTED_MODULE_0__.z.union([textMediaSource,videoMediaSource,audioMediaSource]),source=zod__WEBPACK_IMPORTED_MODULE_0__.z.object({id:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),data:mediaSources}),referenceText=zod__WEBPACK_IMPORTED_MODULE_0__.z.tuple([zod__WEBPACK_IMPORTED_MODULE_0__.z.literal("text"),zod__WEBPACK_IMPORTED_MODULE_0__.z.object({startIdx:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),endIdx:zod__WEBPACK_IMPORTED_MODULE_0__.z.number()})]),referenceVideo=zod__WEBPACK_IMPORTED_MODULE_0__.z.tuple([zod__WEBPACK_IMPORTED_MODULE_0__.z.literal("video"),zod__WEBPACK_IMPORTED_MODULE_0__.z.object({beginTimestamp:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),endTimestamp:zod__WEBPACK_IMPORTED_MODULE_0__.z.string()})]),referenceAudio=zod__WEBPACK_IMPORTED_MODULE_0__.z.tuple([zod__WEBPACK_IMPORTED_MODULE_0__.z.literal("audio"),zod__WEBPACK_IMPORTED_MODULE_0__.z.object({beginTimestamp:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),endTimestamp:zod__WEBPACK_IMPORTED_MODULE_0__.z.string()})]),reference=zod__WEBPACK_IMPORTED_MODULE_0__.z.object({id:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),sourceId:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),data:zod__WEBPACK_IMPORTED_MODULE_0__.z.union([referenceText,referenceVideo,referenceAudio])}),quote=zod__WEBPACK_IMPORTED_MODULE_0__.z.object({id:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),text:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),reference}),claim=zod__WEBPACK_IMPORTED_MODULE_0__.z.custom(),subtopic=zod__WEBPACK_IMPORTED_MODULE_0__.z.object({id:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),title:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),description:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),claims:zod__WEBPACK_IMPORTED_MODULE_0__.z.array(claim)}),topic=zod__WEBPACK_IMPORTED_MODULE_0__.z.object({id:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),title:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),description:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),subtopics:zod__WEBPACK_IMPORTED_MODULE_0__.z.array(subtopic)}),graphics=zod__WEBPACK_IMPORTED_MODULE_0__.z.tuple([zod__WEBPACK_IMPORTED_MODULE_0__.z.literal("piechart"),zod__WEBPACK_IMPORTED_MODULE_0__.z.object({title:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),items:zod__WEBPACK_IMPORTED_MODULE_0__.z.object({label:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),count:zod__WEBPACK_IMPORTED_MODULE_0__.z.number()}).array()})]),reportDataObj=zod__WEBPACK_IMPORTED_MODULE_0__.z.object({title:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),description:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),topics:zod__WEBPACK_IMPORTED_MODULE_0__.z.array(topic),sources:zod__WEBPACK_IMPORTED_MODULE_0__.z.array(source),graphics:graphics.optional(),date:zod__WEBPACK_IMPORTED_MODULE_0__.z.string()}),reportData=zod__WEBPACK_IMPORTED_MODULE_0__.z.tuple([zod__WEBPACK_IMPORTED_MODULE_0__.z.literal("v0.2"),reportDataObj]),openAIModels=zod__WEBPACK_IMPORTED_MODULE_0__.z.enum(["gpt-4","gpt-4-32k","gpt-3.5-turbo","gpt-3.5-turbo-16k","code-davinci-002","code-cushman-001","text-embedding-ada-002","text-davinci-003","text-curie-001","text-babbage-001","text-ada-001"]),anthropicModels=zod__WEBPACK_IMPORTED_MODULE_0__.z.enum(["claude-v1","claude-v1-100k","claude-instant-v1","claude-instant-v1-100k","claude-v1.2","claude-v1.2-100k","claude-v1.3","claude-v1.3-100k","claude-v1.3.1","claude-v1.3.1-100k","claude-v1.4","claude-v1.4-100k"]),models=zod__WEBPACK_IMPORTED_MODULE_0__.z.union([openAIModels,anthropicModels]),pipelineStages=zod__WEBPACK_IMPORTED_MODULE_0__.z.enum(["systemInstructions","clusteringInstructions","extractionInstructions","dedupInstructions"]),tokenCount=zod__WEBPACK_IMPORTED_MODULE_0__.z.object({sent:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),received:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),total:zod__WEBPACK_IMPORTED_MODULE_0__.z.number()}),cost=zod__WEBPACK_IMPORTED_MODULE_0__.z.object({denomination:zod__WEBPACK_IMPORTED_MODULE_0__.z.union([zod__WEBPACK_IMPORTED_MODULE_0__.z.literal("$"),zod__WEBPACK_IMPORTED_MODULE_0__.z.literal("£"),zod__WEBPACK_IMPORTED_MODULE_0__.z.literal("€")]),value:zod__WEBPACK_IMPORTED_MODULE_0__.z.number()}),pipelineStepData=zod__WEBPACK_IMPORTED_MODULE_0__.z.object({temperature:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),tokenCount,costPerToken:cost,model:models,batchSize:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),instructions:zod__WEBPACK_IMPORTED_MODULE_0__.z.string()}),pipelineStep=zod__WEBPACK_IMPORTED_MODULE_0__.z.tuple([pipelineStages,pipelineStepData]),reportMetadataObj=zod__WEBPACK_IMPORTED_MODULE_0__.z.object({buildProcess:zod__WEBPACK_IMPORTED_MODULE_0__.z.array(pipelineStep),startTimestamp:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),duration:zod__WEBPACK_IMPORTED_MODULE_0__.z.number(),totalCost:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),author:zod__WEBPACK_IMPORTED_MODULE_0__.z.string(),organization:zod__WEBPACK_IMPORTED_MODULE_0__.z.string().optional()}),reportMetadata=zod__WEBPACK_IMPORTED_MODULE_0__.z.tuple([zod__WEBPACK_IMPORTED_MODULE_0__.z.literal("v0.2"),reportMetadataObj]);zod__WEBPACK_IMPORTED_MODULE_0__.z.object({data:reportData,metadata:reportMetadata})},"./src/components/claim/Claim.tsx":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{Ay:()=>__WEBPACK_DEFAULT_EXPORT__,CK:()=>Quotes,Pk:()=>Quote,UR:()=>QuoteText,yp:()=>ClaimHeader});var react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__=__webpack_require__("./node_modules/next/dist/compiled/react/jsx-runtime.js"),_elements__WEBPACK_IMPORTED_MODULE_2__=(__webpack_require__("./node_modules/next/dist/compiled/react/index.js"),__webpack_require__("./src/components/elements/index.ts")),_src_assets_icons__WEBPACK_IMPORTED_MODULE_3__=__webpack_require__("./src/assets/icons/index.tsx"),_copyLinkButton_CopyLinkButton__WEBPACK_IMPORTED_MODULE_4__=__webpack_require__("./src/components/copyLinkButton/CopyLinkButton.tsx"),_layout__WEBPACK_IMPORTED_MODULE_5__=__webpack_require__("./src/components/layout/index.ts");function Claim(param){let{claimNum,title,quotes}=param;return(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_elements__WEBPACK_IMPORTED_MODULE_2__.Wu,{className:"py-2 sm:py-2",children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)(_layout__WEBPACK_IMPORTED_MODULE_5__.f,{gap:3,children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(ClaimHeader,{title,claimNum,button:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_copyLinkButton_CopyLinkButton__WEBPACK_IMPORTED_MODULE_4__.A,{anchor:title})}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(Quotes,{quotes})]})})}function ClaimHeader(param){let{title,claimNum,button}=param;return(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)(_layout__WEBPACK_IMPORTED_MODULE_5__.y,{gap:2,className:"justify-between items-start",children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)("p",{className:"text-muted-foreground",children:["Claim#",claimNum]}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{className:"flex flex-grow",children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("p",{className:"text-muted-foreground",children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("a",{id:"".concat(title),children:title})})}),button]})}function QuoteCard(param){let{quote}=param;return(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_elements__WEBPACK_IMPORTED_MODULE_2__.Wu,{className:"p-4 sm:p-4",children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(Quote,{quote})})}function QuoteText(param){let{text}=param;return(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)(_layout__WEBPACK_IMPORTED_MODULE_5__.y,{gap:3,className:"w-full",children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{className:"self-start flex-shrink-0",children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_src_assets_icons__WEBPACK_IMPORTED_MODULE_3__.A.Quote,{className:"h-6 w-4"})}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("p",{className:"flex flex-grow",children:text})]})}function Quote(param){let{quote}=param;return(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)(_layout__WEBPACK_IMPORTED_MODULE_5__.y,{gap:3,children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(QuoteText,{text:quote.text}),(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{className:"h-full self-center flex-shrink-0",children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)("div",{className:"w-6 h-6"})})]})}function Quotes(param){let{quotes}=param;return(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_elements__WEBPACK_IMPORTED_MODULE_2__.Zp,{children:quotes.map(((quote,i)=>(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsxs)(react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.Fragment,{children:[(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(QuoteCard,{quote}),i===quotes.length-1?null:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_elements__WEBPACK_IMPORTED_MODULE_2__.wv,{})]})))})}const __WEBPACK_DEFAULT_EXPORT__=Claim;ClaimHeader.__docgenInfo={description:"Header for the claim components. Takes the form Claim#N ...",methods:[],displayName:"ClaimHeader",props:{title:{required:!0,tsType:{name:"string"},description:""},claimNum:{required:!0,tsType:{name:"number"},description:""},button:{required:!1,tsType:{name:"ReactReactNode",raw:"React.ReactNode"},description:""}}},QuoteCard.__docgenInfo={description:"Single quote - not wrapped in card.",methods:[],displayName:"QuoteCard",props:{quote:{required:!0,tsType:{name:"schema.Quote"},description:""}}},QuoteText.__docgenInfo={description:"",methods:[],displayName:"QuoteText",props:{text:{required:!0,tsType:{name:"string"},description:""}}},Quote.__docgenInfo={description:"",methods:[],displayName:"Quote",props:{quote:{required:!0,tsType:{name:"schema.Quote"},description:""}}},Quotes.__docgenInfo={description:"Creates a column of quotes",methods:[],displayName:"Quotes",props:{quotes:{required:!0,tsType:{name:"Array",elements:[{name:"schema.Quote"}],raw:"schema.Quote[]"},description:""}}},Claim.__docgenInfo={description:"",methods:[],displayName:"Claim",props:{claimNum:{required:!0,tsType:{name:"number"},description:""},title:{required:!0,tsType:{name:"string"},description:""},quotes:{required:!0,tsType:{name:"Array",elements:[{name:"schema.Quote"}],raw:"schema.Quote[]"},description:""}}}},"./src/components/copyLinkButton/CopyLinkButton.tsx":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{A:()=>__WEBPACK_DEFAULT_EXPORT__});var react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__=__webpack_require__("./node_modules/next/dist/compiled/react/jsx-runtime.js"),_elements__WEBPACK_IMPORTED_MODULE_1__=__webpack_require__("./src/components/elements/index.ts"),_src_assets_icons__WEBPACK_IMPORTED_MODULE_2__=__webpack_require__("./src/assets/icons/index.tsx"),sonner__WEBPACK_IMPORTED_MODULE_3__=__webpack_require__("./node_modules/sonner/dist/index.mjs");function CopyLinkButton(param){let{anchor}=param;const notify=async()=>sonner__WEBPACK_IMPORTED_MODULE_3__.oR.success("Success");return(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_elements__WEBPACK_IMPORTED_MODULE_1__.$n,{size:"icon",variant:"outline",onClick:()=>(async()=>navigator.clipboard.writeText(location.protocol+"//"+location.host+location.pathname+"#".concat(encodeURIComponent(anchor))))().then(notify),children:(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_0__.jsx)(_src_assets_icons__WEBPACK_IMPORTED_MODULE_2__.A.Copy,{})})}const __WEBPACK_DEFAULT_EXPORT__=CopyLinkButton;CopyLinkButton.__docgenInfo={description:"",methods:[],displayName:"CopyLinkButton",props:{anchor:{required:!0,tsType:{name:"string"},description:""}}}},"./src/components/layout/index.ts":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{f:()=>Col,y:()=>Row});var jsx_runtime=__webpack_require__("./node_modules/next/dist/compiled/react/jsx-runtime.js"),react=__webpack_require__("./node_modules/next/dist/compiled/react/index.js");__webpack_require__("./src/app/global.css");const classDictRow={0:"gap-x-0",.5:"gap-x-0.5",1:"gap-x-1",1.5:"gap-x-1.5",2:"gap-x-2",2.5:"gap-x-2.5",3:"gap-x-3",3.5:"gap-x-3.5",4:"gap-x-4",5:"gap-x-5",6:"gap-x-6",7:"gap-x-7",8:"gap-x-8",9:"gap-x-9",10:"gap-x-10"},classDictCol={0:"gap-y-0",.5:"gap-y-0.5",1:"gap-y-1",1.5:"gap-y-1.5",2:"gap-y-2",2.5:"gap-y-2.5",3:"gap-y-3",3.5:"gap-y-3.5",4:"gap-y-4",5:"gap-y-5",6:"gap-y-6",7:"gap-y-7",8:"gap-y-8",9:"gap-y-9",10:"gap-y-10"},Row=(0,react.forwardRef)((function Row(param,ref){let{children,className,gap=0,...props}=param;return(0,jsx_runtime.jsx)("div",{...props,ref,className:"flex flex-row ".concat(classDictRow[gap]," ").concat(className),children})})),Col=(0,react.forwardRef)((function Col(param,ref){let{children,className,gap=0,...props}=param;return(0,jsx_runtime.jsx)("div",{...props,ref,className:"flex flex-col ".concat(classDictCol[gap]," ").concat(className),children})}));Row.__docgenInfo={description:"",methods:[],displayName:"Row",props:{gap:{defaultValue:{value:"0",computed:!1},required:!1}}},Col.__docgenInfo={description:"",methods:[],displayName:"Col",props:{gap:{defaultValue:{value:"0",computed:!1},required:!1}}}},"./stories/data/dummyData.ts":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{__webpack_require__.d(__webpack_exports__,{T:()=>reportData});var tttc_common_morphisms_pipeline__WEBPACK_IMPORTED_MODULE_0__=__webpack_require__("../common/morphisms/pipeline.ts");const llmPipeline=__webpack_require__("../common/schema.ts").hr.parse(JSON.parse('{"model":"gpt-4-turbo-preview","data":[{"id":"1","comment":"One concern I have is the privacy of data, whether that can get in the hands of malicious... My recording was cut off when I was saying malicious actors and governments. This is following an extension of where this might be going. In my mind, there\'s a sort of possibility of omniscience where somehow all devices simultaneously are recording what we\'re doing. There\'s incredible power in saying, and there\'s a credible power in collecting data, especially if that can be networked and related to what other people are saying, who\'s relating, interacting with whom, such that you\'re processing now essentially everyone\'s opinions and thoughts within a particular geographic or other context, and able to take that data and crunch it and learn from it. And of course, it also opens up a tremendous amount of power control. Yeah. I\'ll tag onto that. Robert Putnam has wrote extensively on the notion of social capital, and his research that gained a lot of traction in the 90s, early 1000s, was showing a really strong correlation between the degree that people associate with each other in physical spaces and socially desirable outcomes, economic, political, social. And so that raises a couple of questions. One, does a virtual space and a remesh conversation, does that provide enough of that whatever it is that makes associational events so effective? And second question, if not, does it replace and thereby weaken whatever it is about associational life that gives us human or social capital?","interview":"Tarek"},{"id":"2","comment":"I think that, to your point, what is important is to have a follow-on to this, where we\'re all learning the technical skills of what is the division of labor in using any AI-generated or tech tools in a peace-building context, because, you know, that saying of, like, human in the loop, well, this is where the humans must be holding the loop, if the loop is, you know, the conversation and the technology-enhanced part of it is, like, there\'s probably much less that AI can do in peace-building than in, like, the models we see, which are sort of commercial contexts, where it\'s the end goal is a business model, right? It\'s efficiency and shiny things, and in order to preserve, again, like, the most important context, it\'s going to, we\'re going to need to have rules around it for ourselves, like, when is a summary useful, and when can you just not use AI for that? I think that whole division of labor of the conversation of peace-building is really vital, and I hope we get to it, at least I mentioned it, but I hope we get to it more, because certainly where we work in Congress, there are real rules around when there\'s an aperture for more participation and when there\'s not, and when a member has agency and when they don\'t. And so, to the extent that we can even have a template in our minds of, hey, it\'s okay to use it here, but not here, and, you know, we\'re trying to fit this into literally, again, an 18th century structure, and it\'s only going to have little opportunities for using this, but those could be the rudder that sort of turns the aircraft carrier. That\'s why I think it\'s so important.","interview":"Elkay"},{"id":"3","comment":"My main concern, I think, is around bias. There\'s a lot of research on this, that AI is fundamentally biased. This is true also when it sorts out, for example, job applications. It kind of tends to push away applications for people that have already, in a sense, it applies the same bias of its creators into its work. In a sense, this is what concerns me when we try to apply the same technology in other parts of the world that aren\'t the West. Will it have that sort of cultural sensitivity to understand the nuance of a place that does not think and do like its Western creator? And so, yeah, that\'s a little bit my concern, but also something related to our exercise yesterday. When we were using Remesh, it at some point said for a statement that was something like, I wish the US, one of the responses was, I wish the US supported more the peace process between Israel and Palestine. The system classified that statement as negative. So the sentiment, it attached to it a tag of a sentiment negative. Now, as a peace builder, that\'s actually a pretty positive statement. And so my concern is for all sorts of different topics, the sentiments expressed by statements can be, the negative or positive connotation of that statement is completely dependent on the topic. And as peace builders, we also work a lot with that sentiment. So if AI isn\'t able to recognize it, then it might influence our choices in ways that we don\'t want. So again, a lot of this AI work is done together with humans. So there is opportunity for correction, but yeah. And again, I think the predictions, how are these predictions made according to logics that are like very Western-based that might not always apply wherever you do this. And so, like, I completely agree with you and that concern. I wonder if there\'s a way to, for the uses of peace building, to tell an LLM to read or train itself in what is going on in country X, you know, read the newspapers, tune in to conversations that have happened already so that it is, in a sense, prepared to better receive more information and has more context, so to speak, so that when it produces summaries or reports, those summaries and reports are more localized, so to speak. And then another thing, going back to the point that you were making, Lina, about agree disagree, the question I have is if, for the use of peace building and dialogue, some of these tools can be updated with what we know about dialogue tools and to be reflective of better, of a better dialogue experience, if that\'s what we want to do with users, yeah, to use the tool itself as a dialogue experience and not just as data collection.","interview":"Claudia Maffettone"},{"id":"4","comment":"Yeah, I guess, building on the aspect of trust, I think one of my main concerns is an overfitting of tools to context or problems. And really specifically, I don\'t see them as trust-building tools, and I don\'t see them as relationship-building tools, and I don\'t see them as conflict-transforming tools. And I fear that because of the labor that they can reduce and sort of the exciting aspects about them, there is an over-eagerness to apply them as such, when I think we need much more realism about what they are really fitted and able to do, and that is something around information gathering or the deep promotion of violence, or something much more manageable than some of the really normative commitments that we\'re bringing to our hopes for them. I think, just building on that last comment, which of course you don\'t realize I\'m doing because you\'re not getting this sequentially, I\'m concerned about deferring agency or labor to these tools. I think another concern of mine is resource diversion, in that, as we\'ve seen with other shiny tech tools that have come on the scene, we\'re going to see a wave of resources diverted that way that, you know, I don\'t want to live in a zero-sum world, but funding works that way often, in which then some of these human old processes that are low-tech but high-impact can get less attention and less funding. I\'m just interested in having a lot more research on the user experience, the outcomes from a user point of view. Maybe this exists already and I\'m just ignorant about it. But really specifically on these processes that we\'re talking about, that one, having it have to be embedded in a process. It\'s not just we talk about one shot, zero shot LLM prompting, but we\'re also doing zero shot human prompting too. What does this look like to have few or several or fine-tuning within human processes? But then I also wonder about the individual process of codifying belief with agree or disagree buttons in some of the tools that are not qualitative like this one. What does that physical practice of agree, disagree do to my psyche? Is that further entrenching or does that offer invitations to move out of that? Then at the end, I get a graph that says, oh, I sit there. You see this a little bit with political opinion polls where folks just say, oh, I\'m this because I did a quiz and it says I\'m this, so now I\'m this. It\'s like that doesn\'t really offer invitation to challenge or learn to your earlier points. Yeah, just yesterday in our group assignment, in the exercise that we were doing with Remesh, one of our group mates was from the DRC and had a question for Americans. It was essentially like, why aren\'t you intervening in this conflict that you\'ve created here? And there was just that uncomfortable tension of the cobalt in our phones that we are using are such a key driver in that conflict, so I think that\'s a really good point to bring in. To the instinct to play devil\'s advocate, I think one thing that\'s interesting is that like the reason we\'re having this conversation around risks and concerns is because we were prompted to do that way that and I understand you have to scope and like I understand the reasons for doing that but we\'re so naturally inclined to look at multiple different perspectives in one conversation so it\'s even even though we have a clear scope like we want to move other ways and so I feel the personal discomfort of focusing on risks and concerns which I think are super important and I like doing that but I\'m also like inherently a little squirrel who like likes gathering nuts and you know like shiny tools exactly you know and I\'m like inherently optimistic about things too so it does feel like you have to kind of bifurcate in order to stay within scope which I think is interesting and then One more point about kind of incentive structures and use cases that I\'ve been thinking about is that it feels to me that these tools have to be so fit within an existing need or use case that is not sort of purely or solely value or interest driven. And what I mean by that is that I can see the application of this, Talk to City, for specific need of constituents or union leaders who need this to quickly, you know, gather input in order to make a decision. Like that seems like a really clear path. And I think those are the types of things I would rather invest in that gets to sort of nuts and bolts operations that is like, it seems to me like the more invisible it is, the more impactful it would be. And so one of my concerns is sort of the deployment of these just because it\'s kind of cool. And yeah, and it doesn\'t like have a clear path to decision making or like a clear pre-fit need, I guess is what I\'m trying to say.","interview":"Julie Hawke"},{"id":"5","comment":"So, I just want to start from where you ended, because Remesh, by definition, is a commercial tool and sentiment analysis in social media listening and brand analysis is where that\'s coming from. And so, they chose to leave it in, even though for years now, when we\'ve been doing social media listening using Talkwalker or other tools and trying to apply them to our contacts, we\'ve understood that that just doesn\'t work. If you like Nike or don\'t like Nike, that can be a sentiment that you want to track, but don\'t bring that into the space because it\'s not appropriate. So, when we\'re in a world where we\'re sort of the poor people on the block and we just have to take what might work from commercially developed tools, which when you see the latest AI, they\'re focused on like plan your vacation, get your dog to the nearest vet. These are not the issues that we\'re concerned with, right? And so, they\'re building these from an audience that is very Western and then we\'re trying to build upon it, right? But I would say that in my exploration of this, I still believe, as Colleen was saying, when we can try and understand the base foundation models of open AI, anthropic, the meta, the Gemini, all that, and we can continue to try and explore what is harmful with those and how can we create other boundaries around the specific task that we\'re asking it to do with specific data that we\'re asking it to do, I am hopeful that the bias will go down because we\'ll be giving it much more of the context and data around what we want it to do. Let me share just a couple other thoughts. I think that, like you were saying, Meshach, the issue of credibility and legitimacy is real, right? I mean, you can explain that this is the data, here\'s the code, here was the prompt, and people are still going to believe that you deep faked the videos that created the report of Talk to the City, right? Or they\'re going to go and use deep fake videos and come right back at you and say, look, we used the same tool and we actually believe there\'s greater support for Boko Haram than what you found in your research, you know? So I think that credibility is something that doesn\'t have like an end point. It\'s something that we need to really look at. A second thing is that I think that deliberation and even deliberative democracy as a field focuses on also how people learn from each other and evolve. And that means in polarized contexts that we have to understand the polarized relationships. And if people are not building any relationship through their experience of participating in this, we just need to know that. And we need to build the relationships before, after, above it, below it, and not expect that the relationship is going to be built, right? Now people who didn\'t find common ground and then went through Remesh and then you can go back to them and go like, look, you do have common ground, they may experience a certain degree of, wow, I didn\'t realize that, and maybe their stereotypes will lower. But that won\'t depend on the tool. It will depend on how we engage with them. Maybe just two last points. I think there is a fundamental difference, particularly in places where we work in polarized contexts between the inequality of who can write well and text well, clearly ideas. And so I do, and I believe that our Waseem from our Palestinian colleagues have said that. And the last thing I\'ll say is that there\'s something that kind of got me feeling uncomfortable both with Polis and Remesh is the idea that you have to agree and disagree. In a lot of our work, we\'re kind of avoiding asking people the question, do they agree or disagree? And there\'s a lot of peace building methodologies about the spectrum of responses. We have our fist of five thing, and there\'s a lot of things about getting people to agreement where the last thing you would want to do is say yes or no. And what it\'s doing is it\'s saying, you voted like this, you had similar votes in the past, you and this other person, and so it\'s likely that you\'re gonna continue to have similar votes. And yet, it may not always be true, and I also felt a degree of suspicion, and that\'s actually why the Palestinians chose to turn that off in their use of Remesh. I mean, one of the things in some of the conversations I\'ve been having in the last few months is that one of the reasons why all these companies put the model out was because it\'s way cheaper to test it with a whole bunch of people than they having to pay and test it themselves. And then that helps them. And that\'s why, you know, the Google one, when it started saying that the U.S. founding fathers were all Africans, they had to pull it back, right? Because they hadn\'t gone through all the possible testing. So that means that there is a lot of influence that can be done on the large language models, but it remains untransparent. So the opportunity in working with some of these tech partners is that they kind of take the conversational, like the ability to converse from the foundation models, but then they\'re building something on top of it that has parameters that are suited for the context and which can learn in its own cycle. And so, but I think there\'s a lot of questions still, like you wouldn\'t be able to stand up in front of the governor of Bauchi State and be like, let me explain that, you know, the data, where it\'s going. It\'s not like you\'d be able to really, and at this point, clarify, you know, are we really keeping that safe? Is it also influencing the large language models yet? Just a quick question, Shannon, does that, when Remesh is fine tuning its model, do they choose whether it also fine tunes the foundation model or do they have no choice that it also is permeable and going to the foundation model on which they\'ve built theirs? We r done here thanks!","interview":"Lena"},{"id":"6","comment":"My big concern is actually with people trusting too much without understanding the underlying systems. I think we\'ve seen even at this workshop some kind of misunderstandings of what things like probability percentages mean and the kind of false confidence in what are still automated summarizations that are prone to hallucination or even if not explicit hallucination that kind of like over genericness where I think you lose a lot of the real rich insights to dig into that can lead to, that are the things that lead to real relationship building and trust. So I think I\'m most scared of that, yeah, kind of like that false trust and actually moving too quickly with automated summarizations just because they look good and they look plausible. I think another concern I have is one thing that is great about these new tools is it makes it easier for people who\'ve traditionally been, you know, maybe mediators, working in non-tech roles to sort of, you know, build this intuition and experiment with data. But at the end of the day, like, I do think that you still want some of that specialization where, you know, data scientists and data analysts, like, they have a specialized skill set and ways of thinking and asking questions that I think are very complementary. And likewise, people who are really expert and specialized in mediation and building in-person trust and rapport, you know, that\'s enough to focus on full-time. So I\'m worried about just because you kind of can make it easier to merge those roles, I still think there\'s a lot of value in, like, as you said, like, maybe the actually a smarter resource allocation might just be funding a data scientist to work with the piece. And, you know, maybe they\'re working together to use Remesh or POLIS or one of these tools. But I worry that, yeah, because it\'s easier, that actually leads to a loss in the real, like, quality and depth of some of this analysis. I think there is still a danger, depending on a person\'s goals in launching one of these studies, and I think which tech you use might inform that too, of you have an idea of the kind of consensus you want or the kind of bridging you want, and so you really are looking for that and maybe ignoring the parts that you don\'t like to see or prominent, even if they end up at the end as minority views being like, well, we don\'t have to deal with that because we want to focus on the low-hanging fruit, you know, consensus. I think another part of that too is that I think tools like POLIS do well, is making it feel comfortable and safe to voice those minority views, but I think, yeah, ideally there should be something that comes out of that even if it doesn\'t at the end of the day end up as a majority view. Change name Anonymous Yeah, and I think going into, like, how these systems are actually developed, one big elephant in the room is the, like, huge climate and eco-impact of these models, that there\'s something ‑‑ and I mean, obviously, it\'s ‑‑ AI is eating the world, so this isn\'t, like ‑‑ it feels a bit odd to be, like, you know, everyone but the peace building world can use these to improve their workflows or whatever, but at the same time, there\'s something that feels a little bit off about, you know, especially working in contexts whose climate is ‑‑ are being ravaged or the resources are being ravaged to maintain these systems, to be using those same systems for summarization or, yeah, just feels a little bit off. to the to the point of the concern that this will be like just kind of just because you can and it seems cool that there will end up being a lot of use cases just for that without maybe questioning some of the deeper goals and outcomes that also just makes me think of the point oh my god I started that whole My point was about allocation of resources and how resources are very limited in the peace building space. And so if you throw a bunch of money just to run these quick experiments without stepping back and being like, okay, I have a million dollars, so I could either run a hundred kind of random AI-enabled surveys, or maybe that money goes into actually building community and relationship building. So I think there are trade-offs when it comes to where those resources go.","interview":"Emily"},{"id":"7","comment":"I think my main concern, or one of the concerns with current use of deliberation technology is actually not that something goes awry when it is used with good intention, but that the same tools that can enable you to understand and represent a population to achieve their will, those same tools can potentially be used to understand a population in a way that lets you better manipulate them and exert your will upon them. And so how to manage this dual use tradeoff is something that is concerning to me. change name Andrew Konya One concern with certain types of this technology, specifically when it involves recording your voice or recording your videos, is that what comes with that is the fingerprint of your identity. In many situations, your identity being known makes it much less appropriate or much less comfortable or literally can put you at risk to speak honestly and openly about what is important to you. I think one concern or challenge with these technologies is that at the end of the day, it seems that what most people want is to be able to have agency and control over their future and the future of those that they care about. And a lot of times, the more technology that you use, the less transparent that it is, the less clear it is how what you\'re asking people to do is going to actually influence or result in something in the future. And so there\'s, at least right now, still feels like a little bit of a tradeoff between things that are clean and easy to understand, like an election, where people understand how when they cast a vote, it is literally determining the future of who is going to control a country, maybe. But when you\'re participating in these more abstract, deliberative technologies, it is less clear how the very thing that I\'m doing right now is actually going to influence the future for or against the future that I want.","interview":"AK"},{"id":"8","comment":"I\'ve never used WhatsApp before. Do you have to hold it? All right, well, that\'s in the recording now. Is it like a timer on the top bottom? Yes. OK. I know, I totally forgot what I was going to say. Thinking about trust in what\'s coming out of these LLM tools that are really controlled by these big corporate interests and coming back to our world, one thing we\'ve been seeing legislative offices really struggle with recently is the declining trust in the information that they\'re receiving from constituents. We have congressional offices who are getting spammed with phone calls that are LLM-generated fake constituents. And some of them are obviously so. Like recently, a group did a campaign of generated phone calls in the voices of victims of gun violence. And so they would just go through this whole conversation and then at the end say, and all the way, I\'m also dead. Now you should support gun control legislation. So I think that kind of experience is destroying the trust in constituent input that legislators would need to use something like this well. And so that\'s just, they\'re kind of two competing forces here. Like the thing that\'s destroying the trust and then the tools using the same technology that could be rebuilding this trust and finding new scalable ways to tap into constituent input at scale. So I think I\'m a little bit stuck just in the tension there that these two things are not compatible and I don\'t know how to resolve the difference. I can also just share a use case that I\'m really excited about from this. And again, my interest in deliberative tech is just thinking about how can deliberative tech streamline, reduce the friction in some of the democratic processes that are already happening where that friction is too high and it\'s keeping people out of the ability to participate in the system as it is now. Big one is regulatory comments. The Federal Register is awful to comment on regulatory rulemaking in the U.S. and that is a huge area of where policy actually happens and where there are already public participation opportunities built in. They\'re just incredibly hard to access, which means that they\'re overused by the people that can overcome those barriers. So the big companies, the lobbyists who can submit all these comments to the Federal Register and FederalRegister.gov and Rules.gov and whatever. So the ability to kind of tie something like this into that rulemaking process to say this is genuinely open. You don\'t have to know how to write the kind of legalese version of this, but you could record a voice message. You could record a video. That\'s huge for just opening up and reducing some of that friction too. It\'s a really critical piece of policymaking. That\'s not like deliberative like we think about it, like communities talking to each other in conflict and peace building, but just in making it work better. I think that\'s really exciting. I was thinking about that in the context of anonymity, where if we have a massive data set of survey data, there\'s a ton that we can do to anonymize specific identities. But if you have someone in good faith sharing an anecdote about, I don\'t know, say, I feel like I\'m the only lesbian in my small town of Clarkville, Arkansas, that\'s identifiable. And so I\'m thinking just education for people participating in these, for how do I anonymize myself? What should you share and what should you not share? Understanding what could just come out of this. There\'s, to your point about how better design makes people better informed, there\'s a real important level of civics education that is technical for this. I mean, if our civics education, at least in this country, again, is already abysmal, how are we going to do the technical side of civic education on that tier? Did that? Oh, do we need to go?","interview":"Anne"},{"id":"9","comment":"Thanks for this opportunity. You know, when we use the AI for the peace building in Myanmar-Burma context, it seems like the language, the language, the Burmese language, the official Burmese language is not in the, not be usable in most of the LLM platforms. Yeah, that Google translates, there is a process that translation of Myanmar in the Google platform, but it is not from my concern. I mean, as far as I know, it\'s not really 100% correct, accurate, I should say. Yeah, so, and that is one thing, that\'s my concern. Another concern is all the AI, whatever AI contribution is based on the information they have, it has already keyed in, you know. So, the second concern is how much information and from which sources AI already got, even in the English language. Yeah, so this is my two concerns. Thank you. 😊 As I see it, anonymity can give two things, can create two things. One could be to be brave. OK, my name will not be seen or known, so I can speak whatever I have to speak or I want to speak. But on the other hand, then the trust issue, right? Because this is anonymity, and I also don\'t know what this will happen, what I have to contribute, what I contributed to the machine. What could happen? You know, whether it is still there as I say it, as I mean it, or it will be distorted. So that might be also a concern. But this, out of two, I think that the second one could be effectively, how can I say, we can\'t address it. If the user is clear enough that how the AI will process, or whether it\'s their contribution or whatever they have said is, it will remain as is it. So then what I want to say is, it has to be clear how it works. Then the trust issue can be addressed. That\'s what I hope. But I don\'t know how that can be. Yeah, talking about peace building in Burma, Myanmar, is most of the information or the research documents are in English. And there are very, very few papers in Burmese. And when we address the conflict, we would like to, we need to understand the context. So most of the literature or the documents are mostly in Burmese and written by different authors from different ethnic groups. But there has been no place, no organization which is, which like, how can I say, which really oversee all these documents, which are correct, which are not, which are biased. We don\'t know. So that\'s why, go back to where are the sources, the sources of the information that the system is getting and the language. Yeah, I think in the Western world, in the academia, you have this certain, like JSTOR, or certain, you know, organizations which, how can I say? JSTOR, the research, yeah, yeah, yeah. Yeah, so you really, you know, monitor and make sure the facts are, you know, how can I say, well-referenced, right? But in our case, we have some articles and documents in Burmese, but we don\'t have that kind of organization. So that\'s why, how to sensitize, I don\'t know whether it is the correct word, but how to sensitize those articles and those documents are, like, quite, like, if not 100%, but it\'s like 90% reliable to be used as source, you know, by the AI. So that is something that Catherine mentioned, that I think we, back home, there are some organizations which are working on the AI, but they are more on technical perspective, not from the peace-building perspective. So that\'s something that we have to walk on, I think. Yeah, talking about the sources to refer or sources to use by the AI, my experience during my master\'s is that, as Diana mentioned, there were very, very limited resources if we want to write a paper on Myanmar ceasefire situation or peace building. So then, at that time, I remember I referred to like a series of articles, it\'s a booklet actually, on ceasefire on Myanmar produced by East-West Center. So I think I referred that like five, six times in my master paper, master policy paper. But later on, after I did my master, I really started deep conversation with the EROs. Many are wrong. Of course. So from that, that\'s why it\'s like how... These are published literatures, so how can we make the information correct? The correct information are sourced by the AI. I think that\'s the part that my very high concern that I think that we have ways to do so.","interview":"Nang Raw"},{"id":"10","comment":"Where\'s the rest of the. I mean, I guess just to get the conversation started, something that we\'ve all been talking about, something that everyone\'s mentioned, is the potential to misuse these technologies. So it\'s just as easy to, like, kind of use deliberative tech in a way that increases divisiveness instead of trying to bridge gaps. I\'m more parroting what I\'ve heard people bring up in our big discussion groups, but I mean, I feel like with tools like Remesh, you could kind of, if you have bad actors at play, you could kind of frame questions in a way that isn\'t unbiased, in a way that\'s very biased, and then that has the potential to, something that we were mentioning yesterday is, Remesh can show people where they agree on issues, but it can also really show people where they disagree on stuff, and there\'s not really anything in place to bridge what you disagree on, so if questions are kind of framed in a really biased way that increases how many people disagree on something, then that\'s not bringing you together, that\'s just being like, oh, I have nothing in common with these people. Something I noticed yesterday was that Remesh didn\'t get the context. I feel like whoever is creating the poll needs to be very clear in their discussion questions so that the AI can kind of pick it up because when the AI was summarizing people\'s responses it didn\'t know that they were coming from the United States. It said like, this respondent knew that their country had a long history of supporting Israel but the AI didn\'t know what their country was. I think that\'s something that Speak to the City does really well that Remesh was kind of lacking is when Speak to the City has like a summary of like summary of viewpoints it cited like specifically where those came from which I think is really important because it kind of proves that it isn\'t just an AI hallucination it proves that there\'s a real source that this is coming from. Something with just the technology that we kind of mentioned earlier is the lack of transparency and that\'s like not intentional like these companies are trying to be really open about what they\'re doing and how they\'re doing it, but it\'s so complicated that the average person isn\'t going to be able to understand where everything is coming from without like a detailed explanation. Another problem with these platforms is the balancing act of gathering enough data about a person to confirm that it\'s not a bot and to make sure the opinions are authentic but not gathering so much that in these highly polarized contexts, especially in places where there\'s more limited free speech, to make sure that people aren\'t being harmed because they\'re trying to contribute to the discussion. So like with Polis, the only option was to gather your Facebook or Twitter and just put that publicly with each of your comments, which seems terrible. I would never want everything I say to be directly attributable to my social media accounts. And then Remesh is more anonymous, too, but maybe almost too anonymous because it could be attacked by bots, especially if there\'s no CAPTCHA to set up in place.","interview":"Levi"},{"id":"11","comment":"Confirmation bias, it\'s not Catherine with a K, it\'s Catherine with a C. One concern that I have is, if I understand correctly, MLMs are derived from the existing body of discourses that are present in a society or globally. So if the society is already deeply embedded in a polarized context, and especially one in which some of the discourses have structural power over others, does the use of these existing LLMs have a confirmation bias within them towards continually highlighting those discourses that already exist that are part of the sources of those polarizing dynamics? How do they pick up on that which is unique, that which is new ideas which may be almost hidden in terms of their visibility, and enable those to grow and develop and to be generative sources of new ways of thinking and interacting? Yes, I think that\'s part of my concern as well. And I was interested in the earlier discussion about trust. And I think one of Colleen\'s questions was, will people trust these LLMs? And I think that that is still to be seen. But honestly, I think that there\'s another question too, which is when I\'ve done large-scale deliberative dialogue processes where we\'re trying to get the reports back out from the different table groups, often there\'s also a question of, do people trust the people who are theming and writing the reports? Trust in terms of their intent, but also trust in terms of their accuracy and their insight. And I think one of the challenges in highly polarized contexts is the dynamic of polarization means that you don\'t trust those who are the other. That\'s one of the major system rules that\'s creating the polarization is mistrust. So I\'m going to be curious what happens with the use of LLMs in AI. In terms of those dynamics of trust, I think for sure it is one of the spaces that as process designers we have to think about. And transparency and accountability and reliability are things that I think are going to be qualities that must be very intentionally built in to be able to address those in terms of the design of these processes. Can I ask a question about that? Because I think that is, especially in this context, really is core, isn\'t it? And what I see with some of these tools is that they\'re allowing people to be anonymous, like in Polis and Remesh. I\'m wondering, in the Myanmar context, because I know that this is very key. I mean, people are taught from infancy, practically, to fear, right? To be safe is to be afraid. And I\'m wondering if anonymity actually allows people to be more brave. I\'m curious. I don\'t know. I think this has become an interesting thing about, especially in context, like we saw on both the Remesh and on this AI Objectives Talk to the City, you know, Myanmar language is not one of the supported languages, or not the known languages. So is there the possibility of a project of intentionally putting those things in, doing the training work? And I\'m already thinking, and sorry, this is just me, Casino Bee, I\'m always like clicking things. Do you remember the training manual Moonsan did on Deliberative Dialogue Facilitation? And I remember both Janan and you saying, ah, yes, the language is very carefully done. Yes, that\'s right, that\'s right, I remember you saying, and it\'s like, but that would not be something probably any LLM trainer would even know. What would be the role, I mean, in a way, is there an opportunity for those of you who are peace builders, who are trauma healers, in PSSI, you know, people who can actually say, hey, here are some of the things that we find really reliable with a language use that is very sensitive and thoughtful in actually proactively feeding those in, instead of waiting for, I don\'t know, whatever mysterious processes by somebody somewhere or some researchers who are disconnected. And if so, how does that work? How do you do that? I mean, I don\'t even know, how do you begin to do this? So these things that are sources of concerns, in a way, instead of just naming them, it\'s like, where can we find the opportunity and seize that opportunity? But then we need to somehow, I say we, as a friend. But it\'s like, how do we link some of these folks who are maybe even in this conference here to say, hey, wait a minute. We have this. And there\'s maybe some people in the spirit of volunteerism who would be willing, because I don\'t even know. I mean, is it basically just saying, hey, I say Monsan, because it\'s the one I know. Hey, Monsan, can you provide the file to people? And the same thing, I think you can know many, many different ones that you could sort of say. And have that start being the baseline. How do we do this? That is to turn the things that we see as risks into opportunities.","interview":"Katherine Barnes"},{"id":"12","comment":"Do you know anything about Afghanistan? What are the Taliban doing? Are the Taliban suppressing citizens in Afghanistan? Taliban have banned girls from going to school. How many girls are not going to school in Afghanistan? I am concerned Deliberative technologies would be used by the Taliban in Afghanistan to further suppress citizens Taliban may identify citizens who thinks against them or resist them.","interview":"Hayat"}],"title":"test","question":"","description":"","systemInstructions":"","clusteringInstructions":"","extractionInstructions":"","batchSize":10,"dedupInstructions":"","filename":"test-1720484012326","tree":[{"topicName":"Technology in Peace-Building","topicShortDescription":"Exploration of AI and tech tools\' role in facilitating peace and social cohesion.","subtopics":[{"subtopicName":"Technical Skill Development","subtopicShortDescription":"Importance of learning how to effectively integrate AI and technology in peace-building efforts.","claims":[{"claim":"AI has limited applicability in peace-building compared to commercial uses.","quote":"there\'s probably much less that AI can do in peace-building than in, like, the models we see, which are sort of commercial contexts","topicName":"Technology in Peace-Building","subtopicName":"Technical Skill Development","commentId":"2","claimId":"2-0","duplicates":[{"claim":"There needs to be an understanding of when and how AI can be beneficial in peace-building.","quote":"to the extent that we can even have a template in our minds of, hey, it\'s okay to use it here, but not here","topicName":"Technology in Peace-Building","subtopicName":"Technical Skill Development","commentId":"2","claimId":"2-3","duplicated":true},{"claim":"AI contributions in peace-building are limited by the sources of information they have access to.","quote":"all the AI, whatever AI contribution is based on the information they have, it has already keyed in, you know.","topicName":"Technology in Peace-Building","subtopicName":"Technical Skill Development","commentId":"9","claimId":"9-1","duplicated":true}]},{"claim":"Commercially developed tools are often not suitable for specialized non-commercial needs.","quote":"If you like Nike or don\'t like Nike, that can be a sentiment that you want to track, but don\'t bring that into the space because it\'s not appropriate.","topicName":"Technology in Peace-Building","subtopicName":"Technical Skill Development","commentId":"5","claimId":"5-0","duplicates":[{"claim":"Technology tools aimed at social issues must carefully fit the specific needs they\'re meant to address.","quote":"these tools have to be so fit within an existing need or use case that is not sort of purely or solely value or interest driven.","topicName":"Technology in Peace-Building","subtopicName":"Technical Skill Development","commentId":"4","claimId":"4-5","duplicated":true}]},{"claim":"Deliberative technologies can reduce democratic process friction and increase participation.","quote":"Thinking about how can deliberative tech streamline, reduce the friction in some of the democratic processes [...] keeping people out of the ability to participate.","topicName":"Technology in Peace-Building","subtopicName":"Technical Skill Development","commentId":"8","claimId":"8-1","duplicates":[]},{"claim":"There\'s a need to tailor AI systems for peace-building to better reflect local contexts.","quote":"I wonder if there\'s a way to, for the uses of peace building, to tell an LLM to read or train itself in what is going on in country X, [...] so that it is, in a sense, prepared to better receive more information and has more context, so to speak.","topicName":"Technology in Peace-Building","subtopicName":"Technical Skill Development","commentId":"3","claimId":"3-4","duplicates":[]},{"claim":"Specialized skill sets in data science and mediation should remain distinct for effective peace-building.","quote":"I do think that you still want some of that specialization where, you know [...] data scientists and data analysts, like, they have a specialized skill set and ways of thinking and asking questions that I think are very complementary.","topicName":"Technology in Peace-Building","subtopicName":"Technical Skill Development","commentId":"6","claimId":"6-1","duplicates":[]},{"claim":"Peace builders and trauma healers might offer valuable inputs for training sensitive and inclusive LLMs.","quote":"Is there the possibility of a project of intentionally putting those things in, doing the training work?","topicName":"Technology in Peace-Building","subtopicName":"Technical Skill Development","commentId":"11","claimId":"11-6","duplicates":[]}],"claimsCount":9,"subtopicId":"subtopic-0-0"},{"subtopicName":"Human-Machine Collaboration","subtopicShortDescription":"Ensuring human oversight and intervention in AI-powered peace-building processes.","claims":[{"claim":"Incorporating AI into peace-building requires clear rules and guidelines.","quote":"we\'re going to need to have rules around it for ourselves, like, when is a summary useful, and when can you just not use AI for that?","topicName":"Technology in Peace-Building","subtopicName":"Human-Machine Collaboration","commentId":"2","claimId":"2-1","duplicates":[{"claim":"Human oversight is crucial in the AI-driven peace-building process.","quote":"this is where the humans must be holding the loop, if the loop is, you know, the conversation","topicName":"Technology in Peace-Building","subtopicName":"Human-Machine Collaboration","commentId":"2","claimId":"2-2","duplicated":true},{"claim":"AI and technology tools need to be deeply embedded in human processes to be effective.","quote":"having it have to be embedded in a process... What does this look like to have few or several or fine-tuning within human processes?","topicName":"Technology in Peace-Building","subtopicName":"Human-Machine Collaboration","commentId":"4","claimId":"4-4","duplicated":true}]},{"claim":"Virtual spaces may not provide the same social and economic benefits as physical associational life.","quote":"Robert Putnam has wrote extensively on the notion of social capital, and his research [...] was showing a really strong correlation between the degree that people associate with each other in physical spaces and socially desirable outcomes, economic, political, social.","topicName":"Technology in Peace-Building","subtopicName":"Human-Machine Collaboration","commentId":"1","claimId":"1-2","duplicates":[]},{"claim":"AI-powered dialogue tools for peace-building should be adapted to improve the dialogue experience.","quote":"If, for the use of peace building and dialogue, some of these tools can be updated with what we know about dialogue tools and to be reflective of better, of a better dialogue experience.","topicName":"Technology in Peace-Building","subtopicName":"Human-Machine Collaboration","commentId":"3","claimId":"3-5","duplicates":[]}],"claimsCount":5,"subtopicId":"subtopic-0-1"}],"claimsCount":14,"topicId":"topic-0"},{"topicName":"Trust and Technology","topicShortDescription":"Concerns and aspirations regarding the trustworthiness of AI and digital tools in sensitive contexts.","subtopics":[{"subtopicName":"Over reliance on Technology","subtopicShortDescription":"Risks associated with overfitting tech solutions and undermining trust-building.","claims":[{"claim":"Technology tools should not be seen as trust-building mechanisms.","quote":"I don\'t see them as trust-building tools, and I don\'t see them as relationship-building tools, and I don\'t see them as conflict-transforming tools.","topicName":"Trust and Technology","subtopicName":"Over reliance on Technology","commentId":"4","claimId":"4-0","duplicates":[{"claim":"There is an over-eagerness to apply technology tools in ways that are beyond their actual capability.","quote":"I fear that because of the labor that they can reduce and sort of the exciting aspects about them, there is an over-eagerness to apply them as such...","topicName":"Trust and Technology","subtopicName":"Over reliance on Technology","commentId":"4","claimId":"4-1","duplicated":true}]},{"claim":"Trust in the process and outputs of AI is questionable in polarized contexts.","quote":"And I think one of the challenges in highly polarized contexts is the dynamic of polarization means that you don\'t trust those who are the other.","topicName":"Trust and Technology","subtopicName":"Over reliance on Technology","commentId":"11","claimId":"11-2","duplicates":[{"claim":"Transparency, accountability, and reliability must be intentionally incorporated into AI process designs.","quote":"Transparency and accountability and reliability are things that I think are going to be qualities that must be very intentionally built in...","topicName":"Trust and Technology","subtopicName":"Over reliance on Technology","commentId":"11","claimId":"11-3","duplicated":true}]},{"claim":"Transparency in AI operation is difficult for the average person to understand.","quote":"the lack of transparency and that\'s like not intentional like these companies are trying to be really open about what they\'re doing and how they\'re doing it, but it\'s so complicated that the average person isn\'t going to be able to understand","topicName":"Trust and Technology","subtopicName":"Over reliance on Technology","commentId":"10","claimId":"10-3","duplicates":[]},{"claim":"Automated summarizations may lead to a false sense of trust and overlook rich insights.","quote":"I\'m most scared of that, yeah, kind of like that false trust and actually moving too quickly with automated summarizations just because they look good and they look plausible.","topicName":"Trust and Technology","subtopicName":"Over reliance on Technology","commentId":"6","claimId":"6-0","duplicates":[]},{"claim":"AI\'s use in peace-building suffers due to the scarcity of reliable and diverse sources of information.","quote":"how to sensitize those articles and those documents are, like, quite, like, if not 100%, but it\'s like 90% reliable to be used as source, you know, by the AI.","topicName":"Trust and Technology","subtopicName":"Over reliance on Technology","commentId":"9","claimId":"9-5","duplicates":[]},{"claim":"People desire agency and control over their futures, which can be obscured by technology.","quote":"what most people want is to be able to have agency and control over their future... the more technology that you use, the less transparent that it is, the less clear it is how what you\'re asking people to do is going to actually influence or result in something in the future.","topicName":"Trust and Technology","subtopicName":"Over reliance on Technology","commentId":"7","claimId":"7-2","duplicates":[]}],"claimsCount":8,"subtopicId":"subtopic-1-0"},{"subtopicName":"Resource Allocation","subtopicShortDescription":"Worries about diverting funds from human-driven processes to technology.","claims":[{"claim":"Platforms need to ensure contributions are linked to real sources to avoid being seen as AI hallucinations.","quote":"when Speak to the City has like a summary of...it cited like specifically where those came from which I think is really important because it kind of proves that it isn\'t just an AI hallucination","topicName":"Trust and Technology","subtopicName":"Resource Allocation","commentId":"10","claimId":"10-6","duplicates":[]},{"claim":"Resource allocation for AI in peace-building should be carefully considered.","quote":"My point was about allocation of resources and how resources are very limited in the peace building space. And so if you throw a bunch of money just to run these quick experiments without stepping back and being like, okay, I have a million dollars, so I could either run a hundred kind of random AI-enabled surveys, or maybe that money goes into actually building community and relationship building.","topicName":"Trust and Technology","subtopicName":"Resource Allocation","commentId":"6","claimId":"6-4","duplicates":[]},{"claim":"Funding for technology tools might divert resources from effective low-tech processes.","quote":"I\'m concerned about resource diversion, in that, as we\'ve seen with other shiny tech tools that have come on the scene, we\'re going to see a wave of resources diverted that way...","topicName":"Trust and Technology","subtopicName":"Resource Allocation","commentId":"4","claimId":"4-2","duplicates":[]}],"claimsCount":3,"subtopicId":"subtopic-1-1"}],"claimsCount":11,"topicId":"topic-1"},{"topicName":"Misuse and Manipulation","topicShortDescription":"Potential negative applications of deliberative technologies in societal contexts.","subtopics":[{"subtopicName":"Suppressing Dissent","subtopicShortDescription":"Risks of technologies being used to identify and suppress opposition.","claims":[{"claim":"Deliberative technologies can be misused to amplify divisiveness.","quote":"it\'s just as easy to, like, kind of use deliberative tech in a way that increases divisiveness instead of trying to bridge gaps.","topicName":"Misuse and Manipulation","subtopicName":"Suppressing Dissent","commentId":"10","claimId":"10-0","duplicates":[{"claim":"Deliberation technology can be used to manipulate populations.","quote":"those same tools can potentially be used to understand a population in a way that lets you better manipulate them and exert your will upon them.","topicName":"Misuse and Manipulation","subtopicName":"Suppressing Dissent","commentId":"7","claimId":"7-0","duplicated":true},{"claim":"Deliberative technologies can be used to suppress citizens by identifying those who oppose the ruling regime.","quote":"I am concerned Deliberative technologies would be used by the Taliban in Afghanistan to further suppress citizens Taliban may identify citizens who thinks against them or resist them.","topicName":"Misuse and Manipulation","subtopicName":"Suppressing Dissent","commentId":"12","claimId":"12-0","duplicated":true}]},{"claim":"LLM-generated fake constituent interactions diminish trust in constituent input for legislators.","quote":"We have congressional offices who are getting spammed with phone calls that are LLM-generated fake constituents.","topicName":"Misuse and Manipulation","subtopicName":"Suppressing Dissent","commentId":"8","claimId":"8-0","duplicates":[]},{"claim":"The environmental impact of AI technologies is a crucial concern in peace-building contexts.","quote":"One big elephant in the room is the, like, huge climate and eco-impact of these models [...] it feels a little bit off about, you know, especially working in contexts whose climate is ‑‑ are being ravaged or the resources are being ravaged to maintain these systems.","topicName":"Misuse and Manipulation","subtopicName":"Suppressing Dissent","commentId":"6","claimId":"6-3","duplicates":[]},{"claim":"Published literature on Myanmar\'s ceasefire and peace-building may contain inaccuracies.","quote":"Many are wrong. Of course. So from that, that\'s why it\'s like how... These are published literatures, so how can we make the information correct?","topicName":"Misuse and Manipulation","subtopicName":"Suppressing Dissent","commentId":"9","claimId":"9-6","duplicates":[]},{"claim":"Use of certain technologies contributes to conflicts elsewhere, raising ethical concerns.","quote":"the cobalt in our phones that we are using are such a key driver in that conflict...","topicName":"Misuse and Manipulation","subtopicName":"Suppressing Dissent","commentId":"4","claimId":"4-6","duplicates":[]}],"claimsCount":7,"subtopicId":"subtopic-2-0"},{"subtopicName":"Biased Framing","subtopicShortDescription":"Concerns about the framing of discussions leading to increased divisiveness.","claims":[{"claim":"Current methods for accessing public participation opportunities in policymaking are overly complex.","quote":"The Federal Register is awful to comment on regulatory rulemaking in the U.S. [...], which means that they\'re overused by the people that can overcome those barriers.","topicName":"Misuse and Manipulation","subtopicName":"Biased Framing","commentId":"8","claimId":"8-4","duplicates":[]},{"claim":"Deliberative democracy requires understanding and addressing polarized relationships.","quote":"And that means in polarized contexts that we have to understand the polarized relationships.","topicName":"Misuse and Manipulation","subtopicName":"Biased Framing","commentId":"5","claimId":"5-3","duplicates":[]},{"claim":"Deliberative tech questions can be framed to bias the outcome.","quote":"you could kind of frame questions in a way that isn\'t unbiased, in a way that\'s very biased, and then that has the potential to...","topicName":"Misuse and Manipulation","subtopicName":"Biased Framing","commentId":"10","claimId":"10-2","duplicates":[]}],"claimsCount":3,"subtopicId":"subtopic-2-1"}],"claimsCount":10,"topicId":"topic-2"},{"topicName":"Bias in AI","topicShortDescription":"Challenges related to inherent biases within AI systems and their impact.","subtopics":[{"subtopicName":"Cultural Sensitivity","subtopicShortDescription":"Concerns over AI\'s lack of cultural context understanding and perpetuation of creators\' biases.","claims":[{"claim":"AI lacks cultural sensitivity essential for global applicability.","quote":"Will it have that sort of cultural sensitivity to understand the nuance of a place that does not think and do like its Western creator?","topicName":"Bias in AI","subtopicName":"Cultural Sensitivity","commentId":"3","claimId":"3-1","duplicates":[{"claim":"AI predictions and logic may not always be applicable outside of Western contexts.","quote":"How are these predictions made according to logics that are like very Western-based that might not always apply wherever you do this.","topicName":"Bias in AI","subtopicName":"Cultural Sensitivity","commentId":"3","claimId":"3-3","duplicated":true},{"claim":"AI platforms may lack cultural and contextual understanding.","quote":"Remesh didn\'t get the context. [...] the AI didn\'t know what their country was.","topicName":"Bias in AI","subtopicName":"Cultural Sensitivity","commentId":"10","claimId":"10-1","duplicated":true}]},{"claim":"Existing large language models (LLMs) can reinforce confirmation bias in polarized societies.","quote":"So if the society is already deeply embedded in a polarized context, and especially one in which some of the discourses have structural power over others, does the use of these existing LLMs have a confirmation bias within them towards continually highlighting those discourses that already exist...","topicName":"Bias in AI","subtopicName":"Cultural Sensitivity","commentId":"11","claimId":"11-0","duplicates":[{"claim":"LLMs may struggle to identify and amplify new and unique ideas in polarized contexts.","quote":"How do they pick up on that which is unique, that which is new ideas which may be almost hidden in terms of their visibility, and enable those to grow and develop...","topicName":"Bias in AI","subtopicName":"Cultural Sensitivity","commentId":"11","claimId":"11-1","duplicated":true}]},{"claim":"AI systems intrinsically manifest the biases of their creators.","quote":"AI is fundamentally biased. [...] It kind of tends to push away applications for people that have already, in a sense, it applies the same bias of its creators into its work.","topicName":"Bias in AI","subtopicName":"Cultural Sensitivity","commentId":"3","claimId":"3-0","duplicates":[]},{"claim":"Bias in AI can be reduced by providing more context and data.","quote":"I am hopeful that the bias will go down because we\'ll be giving it much more of the context and data around what we want it to do.","topicName":"Bias in AI","subtopicName":"Cultural Sensitivity","commentId":"5","claimId":"5-1","duplicates":[]},{"claim":"There is a lack of reliable, centralized verification for information and documents in Burmese.","quote":"there has been no place, no organization which is, which like, how can I say, which really oversee all these documents, which are correct, which are not, which are biased.","topicName":"Bias in AI","subtopicName":"Cultural Sensitivity","commentId":"9","claimId":"9-4","duplicates":[]}],"claimsCount":8,"subtopicId":"subtopic-3-0"},{"subtopicName":"Misinterpretation of Sentiments","subtopicShortDescription":"Issues around AI misclassifying sentiments and the need for localized understanding.","claims":[{"claim":"AI\'s sentiment analysis can misinterpret peace-building statements as negative.","quote":"The system classified that statement as negative. [...] So the sentiment, it attached to it a tag of a sentiment negative.","topicName":"Bias in AI","subtopicName":"Misinterpretation of Sentiments","commentId":"3","claimId":"3-2","duplicates":[]}],"claimsCount":1,"subtopicId":"subtopic-3-1"}],"claimsCount":9,"topicId":"topic-3"},{"topicName":"Anonymity and Participation","topicShortDescription":"The dual nature of anonymity in encouraging participation and potentially eroding trust.","subtopics":[{"subtopicName":"Trust and Verification","subtopicShortDescription":"Challenges in establishing trust in contributions while maintaining anonymity.","claims":[{"claim":"Large datasets make total anonymity challenging in the case of unique personal anecdotes.","quote":"If we have a massive data set of survey data, there\'s [...] identifiable.","topicName":"Anonymity and Participation","subtopicName":"Trust and Verification","commentId":"8","claimId":"8-2","duplicates":[]},{"claim":"Replacing physical associational events with virtual ones might weaken the social capital that benefits society.","quote":"One, does a virtual space and a remesh conversation, does that provide enough of that whatever it is that makes associational events so effective? And second question, if not, does it replace and thereby weaken whatever it is about associational life that gives us human or social capital?","topicName":"Anonymity and Participation","subtopicName":"Trust and Verification","commentId":"1","claimId":"1-3","duplicates":[]},{"claim":"Anonymity in deliberative platforms can be too excessive, risking bot attacks.","quote":"Remesh is more anonymous, too, but maybe almost too anonymous because it could be attacked by bots, especially if there\'s no CAPTCHA to set up in place.","topicName":"Anonymity and Participation","subtopicName":"Trust and Verification","commentId":"10","claimId":"10-5","duplicates":[]},{"claim":"Proper explanation of AI processes can address trust issues related to anonymity.","quote":"If the user is clear enough that how the AI will process, or whether it\'s their contribution or whatever they have said is, it will remain as is it. So then what I want to say is, it has to be clear how it works. Then the trust issue can be addressed.","topicName":"Anonymity and Participation","subtopicName":"Trust and Verification","commentId":"9","claimId":"9-3","duplicates":[]},{"claim":"The process of codifying belief through agree or disagree actions in tools might influence individual psyche.","quote":"What does that physical practice of agree, disagree do to my psyche? Is that further entrenching or does that offer invitations to move out of that?","topicName":"Anonymity and Participation","subtopicName":"Trust and Verification","commentId":"4","claimId":"4-3","duplicates":[]}],"claimsCount":5,"subtopicId":"subtopic-4-0"},{"subtopicName":"Freedom to Speak","subtopicShortDescription":"How anonymity can empower individuals to share openly.","claims":[{"claim":"Anonymity in AI can both empower individuals to speak freely and create trust issues.","quote":"anonymity can give two things, can create two things. One could be to be brave... But on the other hand, then the trust issue.","topicName":"Anonymity and Participation","subtopicName":"Freedom to Speak","commentId":"9","claimId":"9-2","duplicates":[{"claim":"Anonymity in AI and deliberation platforms may help participants to express themselves more freely.","quote":"I\'m wondering if anonymity actually allows people to be more brave.","topicName":"Anonymity and Participation","subtopicName":"Freedom to Speak","commentId":"11","claimId":"11-4","duplicated":true}]},{"claim":"Binary agree/disagree mechanisms may not be suitable for all contexts of engagement.","quote":"there\'s something that kind of got me feeling uncomfortable both with Polis and Remesh is the idea that you have to agree and disagree.","topicName":"Anonymity and Participation","subtopicName":"Freedom to Speak","commentId":"5","claimId":"5-5","duplicates":[]},{"claim":"Tools that facilitate anonymity can make it safer to express minority views.","quote":"Tools like POLIS do well, is making it feel comfortable and safe to voice those minority views.","topicName":"Anonymity and Participation","subtopicName":"Freedom to Speak","commentId":"6","claimId":"6-2","duplicates":[]}],"claimsCount":4,"subtopicId":"subtopic-4-1"}],"claimsCount":9,"topicId":"topic-4"},{"topicName":"Privacy and Data Security","topicShortDescription":"Considerations around the protection of individual data and privacy.","subtopics":[{"subtopicName":"Data Misuse","subtopicShortDescription":"Risks of personal data falling into the wrong hands, including malicious actors and governments.","claims":[{"claim":"The aggregation of data from various sources can lead to a form of omniscience by governments or malicious actors.","quote":"In my mind, there\'s a sort of possibility of omniscience where somehow all devices simultaneously are recording what we\'re doing. There\'s incredible power in saying, and there\'s a credible power in collecting data, especially if that can be networked and related to what other people are saying, who\'s relating, interacting with whom, such that you\'re processing now essentially everyone\'s opinions and thoughts within a particular geographic or other context, and able to take that data and crunch it and learn from it.","topicName":"Privacy and Data Security","subtopicName":"Data Misuse","commentId":"1","claimId":"1-0","duplicates":[]},{"claim":"Testing AI models publicly can reduce development costs for companies.","quote":"one of the reasons why all these companies put the model out was because it\'s way cheaper to test it with a whole bunch of people than they having to pay and test it themselves.","topicName":"Privacy and Data Security","subtopicName":"Data Misuse","commentId":"5","claimId":"5-6","duplicates":[]},{"claim":"Balancing data collection for authenticity and user safety is challenging.","quote":"balancing act of gathering enough data about a person to confirm that it\'s not a bot and to make sure the opinions are authentic but not gathering so much that [...] to make sure that people aren\'t being harmed","topicName":"Privacy and Data Security","subtopicName":"Data Misuse","commentId":"10","claimId":"10-4","duplicates":[]},{"claim":"Technology identifying individuals might risk their safety and hinder honest participation.","quote":"In many situations, your identity being known makes it much less appropriate or much less comfortable or literally can put you at risk to speak honestly and openly about what is important to you.","topicName":"Privacy and Data Security","subtopicName":"Data Misuse","commentId":"7","claimId":"7-1","duplicates":[]}],"claimsCount":4,"subtopicId":"subtopic-5-0"},{"subtopicName":"Surveillance Concerns","subtopicShortDescription":"Worries about extensive monitoring and data collection leading to a form of omniscience.","claims":[{"claim":"Extensive monitoring and data collection pose risks to personal privacy and could be used for power control.","quote":"There\'s incredible power in collecting data, [...] and able to take that data and crunch it and learn from it. And of course, it also opens up a tremendous amount of power control.","topicName":"Privacy and Data Security","subtopicName":"Surveillance Concerns","commentId":"1","claimId":"1-1","duplicates":[]}],"claimsCount":1,"subtopicId":"subtopic-5-1"}],"claimsCount":5,"topicId":"topic-5"},{"topicName":"Access and Inclusion","topicShortDescription":"Exploring the inclusivity of technology with respect to language and representation.","subtopics":[{"subtopicName":"Language Barriers","subtopicShortDescription":"The limitations faced by non-English speakers in engaging with AI-based platforms.","claims":[{"claim":"AI language models do not effectively support the Burmese language.","quote":"when we use the AI for the peace building in Myanmar-Burma context, it seems like the language, the Burmese language, the official Burmese language is not in the, not be usable in most of the LLM platforms.","topicName":"Access and Inclusion","subtopicName":"Language Barriers","commentId":"9","claimId":"9-0","duplicates":[{"claim":"The lack of support for local languages in LLMs limits their applicability and inclusivity.","quote":"Myanmar language is not one of the supported languages, or not the known languages.","topicName":"Access and Inclusion","subtopicName":"Language Barriers","commentId":"11","claimId":"11-5","duplicated":true,"duplicates":[]}]},{"claim":"Language proficiency inequality can affect participation in deliberative processes.","quote":"there is a fundamental difference, particularly in places where we work in polarized contexts between the inequality of who can write well and text well, clearly ideas.","topicName":"Access and Inclusion","subtopicName":"Language Barriers","commentId":"5","claimId":"5-4","duplicates":[]}],"claimsCount":3,"subtopicId":"subtopic-6-0"},{"subtopicName":"Representative Data","subtopicShortDescription":"The need for diverse and accurate data sources to inform AI systems.","claims":[{"claim":"Technical civics education is crucial for participatory technologies.","quote":"There\'s [...] a real important level of civics education that is technical for this.","topicName":"Access and Inclusion","subtopicName":"Representative Data","commentId":"8","claimId":"8-3","duplicates":[]}],"claimsCount":1,"subtopicId":"subtopic-6-1"}],"claimsCount":4,"topicId":"topic-6"}],"costs":0.6768200000000001,"start":1720484012969,"unmatchedClaims":[{"claim":"Technology\'s credibility is constantly questioned in public discourse.","quote":"People are still going to believe that you deep faked the videos that created the report of Talk to the City.","topicName":"Trust and Technology","sub-topticName":"Over reliance on Technology","commentId":"5","claimId":"5-2"},{"claim":"The influence of citizen\'s actions on future outcomes is clearer in traditional methods like elections than in deliberative technologies.","quote":"things that are clean and easy to understand, like an election, where people understand how when they cast a vote, it is literally determining the future... But when you\'re participating in these more abstract, deliberative technologies, it is less clear how the very thing that I\'m doing right now is actually going to influence the future for or against the future that I want.","topicName":"Trust and Technology","subtemperatureName":"Resource Allocation","commentId":"7","claimId":"7-3"}],"prompt_tokens":46409,"completion_tokens":7091,"end":1720484147615,"duration":"2 minutes 14.645999999999987 seconds"}')),reportData=(0,tttc_common_morphisms_pipeline__WEBPACK_IMPORTED_MODULE_0__.kW)(llmPipeline)}}]);